{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "eeg_cnn_lib.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHTlN4tTxW9Z",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeQF2BsueSwZ",
        "colab_type": "code",
        "outputId": "8bf42d3b-d1d1-4fc2-c1a2-ab5117d39746",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 730
        }
      },
      "source": [
        "!pip install git+https://github.com/Theano/Theano\n",
        "!pip install git+https://github.com/Lasagne/Lasagne\n",
        "!pip install git+https://github.com/tariqdaouda/Mariana"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/Theano/Theano\n",
            "  Cloning https://github.com/Theano/Theano to /tmp/pip-req-build-x2sn61nl\n",
            "  Running command git clone -q https://github.com/Theano/Theano /tmp/pip-req-build-x2sn61nl\n",
            "Requirement already satisfied (use --upgrade to upgrade): Theano==1.0.4+51.gf1e4ec47c from git+https://github.com/Theano/Theano in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from Theano==1.0.4+51.gf1e4ec47c) (1.18.4)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Theano==1.0.4+51.gf1e4ec47c) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Theano==1.0.4+51.gf1e4ec47c) (1.12.0)\n",
            "Building wheels for collected packages: Theano\n",
            "  Building wheel for Theano (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Theano: filename=Theano-1.0.4+51.gf1e4ec47c-cp36-none-any.whl size=2667983 sha256=d9bb0f21d987ca3f7341b2bb39a4c73faf8768496246dae224dc99f4545e3a6d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-u00wyh4f/wheels/64/f2/f4/6b1f50baf18aca2eab5d9b5a431b90e3d8be4711c8f7457eb7\n",
            "Successfully built Theano\n",
            "Collecting git+https://github.com/Lasagne/Lasagne\n",
            "  Cloning https://github.com/Lasagne/Lasagne to /tmp/pip-req-build-kmxaa20r\n",
            "  Running command git clone -q https://github.com/Lasagne/Lasagne /tmp/pip-req-build-kmxaa20r\n",
            "Requirement already satisfied (use --upgrade to upgrade): Lasagne==0.2.dev1 from git+https://github.com/Lasagne/Lasagne in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from Lasagne==0.2.dev1) (1.18.4)\n",
            "Building wheels for collected packages: Lasagne\n",
            "  Building wheel for Lasagne (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Lasagne: filename=Lasagne-0.2.dev1-cp36-none-any.whl size=122797 sha256=4271e2d2c25b7e1905618f870332cbb469173fcf62ea740d85d9d8550ee4bb23\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4s50hsk7/wheels/c4/20/90/9f7242c381402829c5918261e3eb51a87bc1d8521456749b57\n",
            "Successfully built Lasagne\n",
            "Collecting git+https://github.com/tariqdaouda/Mariana\n",
            "  Cloning https://github.com/tariqdaouda/Mariana to /tmp/pip-req-build-xeltjwnp\n",
            "  Running command git clone -q https://github.com/tariqdaouda/Mariana /tmp/pip-req-build-xeltjwnp\n",
            "Requirement already satisfied (use --upgrade to upgrade): Mariana==2.0.0rc1 from git+https://github.com/tariqdaouda/Mariana in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: theano in /usr/local/lib/python3.6/dist-packages (from Mariana==2.0.0rc1) (1.0.4+51.gf1e4ec47c)\n",
            "Requirement already satisfied: pyGeno in /usr/local/lib/python3.6/dist-packages (from Mariana==2.0.0rc1) (2.0.0)\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.6/dist-packages (from Mariana==2.0.0rc1) (3.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from Mariana==2.0.0rc1) (1.18.4)\n",
            "Requirement already satisfied: Lasagne in /usr/local/lib/python3.6/dist-packages (from Mariana==2.0.0rc1) (0.2.dev1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from theano->Mariana==2.0.0rc1) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from theano->Mariana==2.0.0rc1) (1.4.1)\n",
            "Requirement already satisfied: rabaDB>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from pyGeno->Mariana==2.0.0rc1) (2.0)\n",
            "Building wheels for collected packages: Mariana\n",
            "  Building wheel for Mariana (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Mariana: filename=Mariana-2.0.0rc1-cp36-none-any.whl size=56456 sha256=bab3933a83f789db452f617ee38ff6148d751eadd4deafccb2804a565c11bba9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ukzjxtz7/wheels/1f/ca/1b/22d3ed05d19c6b64cb8bd1e926058a1cf23ede03cc3a0d2eda\n",
            "Successfully built Mariana\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dM2z04Ywv6h",
        "colab_type": "code",
        "outputId": "1ef3e2f1-cd6e-49a9-e116-9571356aeec1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "import math as m\n",
        "import numpy as np\n",
        "np.random.seed(123)\n",
        "import scipy.io\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "def cart2sph(x, y, z):\n",
        "    x2_y2 = x**2 + y**2\n",
        "    r = m.sqrt(x2_y2 + z**2)                    \n",
        "    elev = m.atan2(z, m.sqrt(x2_y2))            \n",
        "    az = m.atan2(y, x)                        \n",
        "    return r, elev, az\n",
        "\n",
        "\n",
        "def pol2cart(theta, rho):\n",
        "    return rho * m.cos(theta), rho * m.sin(theta)\n",
        "\n",
        "\n",
        "def augment_EEG(data, stdMult, pca=False, n_components=2):\n",
        "    \n",
        "    augData = np.zeros(data.shape)\n",
        "    if pca:\n",
        "        pca = PCA(n_components=n_components)\n",
        "        pca.fit(data)\n",
        "        components = pca.components_\n",
        "        variances = pca.explained_variance_ratio_\n",
        "        coeffs = np.random.normal(scale=stdMult, size=pca.n_components) * variances\n",
        "        for s, sample in enumerate(data):\n",
        "            augData[s, :] = sample + (components * coeffs.reshape((n_components, -1))).sum(axis=0)\n",
        "    else:\n",
        "        for f, feat in enumerate(data.transpose()):\n",
        "            augData[:, f] = feat + np.random.normal(scale=stdMult*np.std(feat), size=feat.size)\n",
        "    return augData\n",
        "\n",
        "\n",
        "def augment_EEG_image(image, std_mult, pca=False, n_components=2):\n",
        "    \n",
        "    augData = np.zeros((data.shape[0], data.shape[1], data.shape[2] * data.shape[3]))\n",
        "    for c in xrange(image.shape[1]):\n",
        "        reshData = np.reshape(data['featMat'][:, c, :, :], (data['featMat'].shape[0], -1))\n",
        "        if pca:\n",
        "            augData[:, c, :] = augment_EEG(reshData, std_mult, pca=True, n_components=n_components)\n",
        "        else:\n",
        "            augData[:, c, :] = augment_EEG(reshData, std_mult, pca=False)\n",
        "    return np.reshape(augData, data['featMat'].shape)\n",
        "\n",
        "\n",
        "def load_data(data_file):\n",
        "   \n",
        "    print(\"Loading data from %s\" % (data_file))\n",
        "\n",
        "    dataMat = scipy.io.loadmat(data_file, mat_dtype=True)\n",
        "\n",
        "    print(\"Data loading complete. Shape is %r\" % (dataMat['featMat'].shape,))\n",
        "    return dataMat['features'][:, :-1], dataMat['features'][:, -1] - 1   \n",
        "\n",
        "def reformatInput(data, labels, indices):\n",
        "   \n",
        "    trainIndices = indices[0][len(indices[1]):]\n",
        "    validIndices = indices[0][:len(indices[1])]\n",
        "    testIndices = indices[1]\n",
        "    \n",
        "    if data.ndim == 4:\n",
        "        return [(data[trainIndices], np.squeeze(labels[trainIndices]).astype(np.int32)),\n",
        "                (data[validIndices], np.squeeze(labels[validIndices]).astype(np.int32)),\n",
        "                (data[testIndices], np.squeeze(labels[testIndices]).astype(np.int32))]\n",
        "    elif data.ndim == 5:\n",
        "        return [(data[:, trainIndices], np.squeeze(labels[trainIndices]).astype(np.int32)),\n",
        "                (data[:, validIndices], np.squeeze(labels[validIndices]).astype(np.int32)),\n",
        "                (data[:, testIndices], np.squeeze(labels[testIndices]).astype(np.int32))]\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    data = np.random.normal(size=(100, 10))\n",
        "    print('Original: {0}'.format(data))   \n",
        "    print('Augmented: {0}'.format(augment_EEG(data, 0.1, pca=True)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original: [[-1.08563060e+00  9.97345447e-01  2.82978498e-01 -1.50629471e+00\n",
            "  -5.78600252e-01  1.65143654e+00 -2.42667924e+00 -4.28912629e-01\n",
            "   1.26593626e+00 -8.66740402e-01]\n",
            " [-6.78886152e-01 -9.47089689e-02  1.49138963e+00 -6.38901997e-01\n",
            "  -4.43981960e-01 -4.34351276e-01  2.20593008e+00  2.18678609e+00\n",
            "   1.00405390e+00  3.86186399e-01]\n",
            " [ 7.37368576e-01  1.49073203e+00 -9.35833868e-01  1.17582904e+00\n",
            "  -1.25388067e+00 -6.37751502e-01  9.07105196e-01 -1.42868070e+00\n",
            "  -1.40068720e-01 -8.61754896e-01]\n",
            " [-2.55619371e-01 -2.79858911e+00 -1.77153310e+00 -6.99877235e-01\n",
            "   9.27462432e-01 -1.73635683e-01  2.84591590e-03  6.88222711e-01\n",
            "  -8.79536343e-01  2.83627324e-01]\n",
            " [-8.05366518e-01 -1.72766949e+00 -3.90899794e-01  5.73805862e-01\n",
            "   3.38589051e-01 -1.18304945e-02  2.39236527e+00  4.12912160e-01\n",
            "   9.78736006e-01  2.23814334e+00]\n",
            " [-1.29408532e+00 -1.03878821e+00  1.74371223e+00 -7.98062735e-01\n",
            "   2.96832303e-02  1.06931597e+00  8.90706391e-01  1.75488618e+00\n",
            "   1.49564414e+00  1.06939267e+00]\n",
            " [-7.72708714e-01  7.94862668e-01  3.14271995e-01 -1.32626546e+00\n",
            "   1.41729905e+00  8.07236535e-01  4.54900806e-02 -2.33092061e-01\n",
            "  -1.19830114e+00  1.99524074e-01]\n",
            " [ 4.68439119e-01 -8.31154984e-01  1.16220405e+00 -1.09720305e+00\n",
            "  -2.12310035e+00  1.03972709e+00 -4.03366038e-01 -1.26029585e-01\n",
            "  -8.37516723e-01 -1.60596276e+00]\n",
            " [ 1.25523737e+00 -6.88868984e-01  1.66095249e+00  8.07308186e-01\n",
            "  -3.14758147e-01 -1.08590240e+00 -7.32461987e-01 -1.21252313e+00\n",
            "   2.08711336e+00  1.64441230e-01]\n",
            " [ 1.15020554e+00 -1.26735205e+00  1.81035130e-01  1.17786194e+00\n",
            "  -3.35010762e-01  1.03111446e+00 -1.08456791e+00 -1.36347154e+00\n",
            "   3.79400612e-01 -3.79176435e-01]\n",
            " [ 6.42054689e-01 -1.97788793e+00  7.12264635e-01  2.59830393e+00\n",
            "  -2.46259814e-02  3.41421289e-02  1.79549485e-01 -1.86197571e+00\n",
            "   4.26146640e-01 -1.60540974e+00]\n",
            " [-4.27679598e-01  1.24286955e+00 -7.35216956e-01  5.01248990e-01\n",
            "   1.01273905e+00  2.78740856e-01 -1.37094847e+00 -3.32475275e-01\n",
            "   1.95941134e+00 -2.02504576e+00]\n",
            " [-2.75786014e-01 -5.52108071e-01  1.20747363e-01  7.48215617e-01\n",
            "   1.60869097e+00 -2.70232392e-01  8.12341330e-01  4.99740145e-01\n",
            "   4.74347298e-01 -5.63923932e-01]\n",
            " [-9.97321469e-01 -1.10004311e+00 -7.56437209e-01  3.21686576e-01\n",
            "   7.60949393e-01  3.23468848e-01 -5.48955096e-01  1.80597011e+00\n",
            "   1.51886562e+00 -3.54000113e-01]\n",
            " [-8.23431406e-01  1.30214954e-01  1.26729865e+00  3.32764977e-01\n",
            "   5.56548705e-01 -2.12080122e-01  4.56270895e-01  1.54454445e+00\n",
            "  -2.39668781e-01  1.43307733e-01]\n",
            " [ 2.53816477e-01  2.83725356e-01 -1.41188888e+00 -1.87686866e+00\n",
            "  -1.01965507e+00  1.67942295e-01  5.53856166e-01 -5.30674560e-01\n",
            "   1.37725748e+00 -1.43175974e-01]\n",
            " [ 2.03159982e-02 -1.93963871e-01  1.34026793e-01  7.04474074e-01\n",
            "   6.65653438e-01 -8.98422941e-01  1.52366378e+00 -1.09502646e+00\n",
            "   7.92270141e-02 -2.74396574e-01]\n",
            " [-1.04899168e+00 -7.51205880e-02 -7.40813773e-01  7.29072433e-02\n",
            "   4.03085961e-01  1.47192937e+00  3.07384219e-01 -6.11225340e-01\n",
            "  -3.91619811e-01  1.39978106e-01]\n",
            " [ 9.34608295e-02  1.45958927e+00  1.39535293e+00 -3.58935926e-01\n",
            "  -5.48642128e-01 -2.55705460e+00 -5.48920413e-01 -9.78057706e-01\n",
            "  -3.54824458e-01  3.91584242e-01]\n",
            " [ 1.77192329e-01 -2.99680070e-02  1.99582111e-01 -1.26117773e-01\n",
            "   1.97018933e-01 -3.23105501e+00 -2.69293490e-01 -1.10850721e-01\n",
            "  -3.41261716e-01 -2.17946262e-01]\n",
            " [ 7.03310118e-01 -5.98105331e-01  2.20070210e+00  6.88296930e-01\n",
            "  -6.30725091e-03 -2.06662303e-01 -8.65222864e-02 -9.15307070e-01\n",
            "  -9.52025393e-02  2.78683517e-01]\n",
            " [ 5.79541616e-01  5.79689779e-01 -2.74877547e-01 -1.41608225e+00\n",
            "  -6.69102626e-01  1.61219304e+00  8.96058313e-01  3.69619586e-01\n",
            "  -7.61294245e-01  3.64515497e-03]\n",
            " [-1.25566869e+00 -5.51936876e-01 -2.45203342e-01 -3.61639932e-01\n",
            "   9.56601931e-01 -1.41872591e+00 -8.65432272e-01 -1.37468797e+00\n",
            "  -1.23735321e+00  1.24055896e-01]\n",
            " [-1.60044053e+00  7.53868779e-01 -2.46815777e-01  6.87883325e-02\n",
            "   3.22576738e-01 -4.34166520e-01  1.03247972e+00 -1.94342727e-01\n",
            "   5.94070255e-01 -1.99112383e-01]\n",
            " [ 2.90874387e-01  2.79662670e-01  2.49969939e-01 -9.74307850e-01\n",
            "   4.35875771e-01 -3.18956989e-01  6.30488030e-01 -2.15249344e+00\n",
            "  -1.46511622e+00  3.63445562e-01]\n",
            " [ 1.86292759e+00  8.35058747e-01 -6.82450934e-01 -1.69205242e+00\n",
            "   7.42686221e-01 -8.05832220e-02  5.90704218e-01  1.15298722e-01\n",
            "   2.96429251e-02  2.95862545e+00]\n",
            " [-6.12996105e-03 -1.59245209e-01 -1.21448675e-01 -5.83536717e-01\n",
            "   9.90132895e-01 -3.53754334e-01  6.35942706e-01  2.84603030e-01\n",
            "   1.21898586e+00  4.20179597e-01]\n",
            " [-1.21338478e+00 -1.32648779e+00  1.40836915e+00 -6.08710803e-01\n",
            "  -1.32060258e+00 -6.69618600e-01  1.26462529e+00 -1.42021300e+00\n",
            "  -8.66495204e-01 -6.66807509e-01]\n",
            " [-1.25118987e+00 -1.18432734e+00 -1.51810798e+00 -4.61187413e-01\n",
            "  -3.54908832e-01 -6.82538154e-01 -1.65369784e+00  1.25333595e+00\n",
            "  -1.32907883e+00  2.78033712e-01]\n",
            " [-1.07476659e+00  6.68316867e-01  9.55832355e-01 -8.77613587e-01\n",
            "  -1.92371573e+00  6.95787319e-01  1.87580055e+00  4.15694540e-01\n",
            "   1.60544421e-01  8.19760610e-01]\n",
            " [ 7.65054846e-01 -8.28988834e-01 -6.59151311e-01  6.11123550e-01\n",
            "  -1.44013347e-01  1.31660560e+00 -7.04342147e-01  7.50609917e-01\n",
            "   3.42637981e-01 -1.26437564e-01]\n",
            " [ 1.17591077e+00  6.80071533e-01 -1.00496715e+00  6.40218680e-01\n",
            "   1.37499063e+00 -1.30444689e-01 -2.48655850e-01 -6.69647148e-01\n",
            "  -1.36038857e-02  6.86200686e-01]\n",
            " [-8.17668300e-01 -1.34635756e+00 -3.75749911e-01 -1.37972498e+00\n",
            "   5.23218441e-01 -4.26689770e-01 -1.75540184e+00 -3.48607515e-01\n",
            "  -1.92614986e-01  4.49135613e-01]\n",
            " [-1.45363543e-01  1.86872646e+00 -5.18703852e-01 -6.23985486e-02\n",
            "  -1.02910614e-01 -2.82628384e-01  1.42425585e-01  5.41231297e-01\n",
            "   1.34009870e+00 -1.56925613e+00]\n",
            " [-5.10342874e-01 -4.47771425e-01  9.37850297e-01 -3.56663061e-01\n",
            "  -1.89517559e+00  8.77304639e-02 -3.36892315e-02  1.79751566e-01\n",
            "  -1.04016288e+00  1.71903468e+00]\n",
            " [-3.23859784e-01 -1.88296858e-01 -9.00008570e-01 -9.31002004e-01\n",
            "  -1.22273696e+00 -3.93310852e-01 -9.57581839e-01  2.05646734e+00\n",
            "  -1.88849238e+00 -1.12833055e+00]\n",
            " [-4.01414428e-01  6.73491278e-01 -4.13756881e-01  6.75963393e-01\n",
            "  -9.86803889e-01  5.92911339e-02  1.74404109e+00 -9.67744396e-01\n",
            "   4.19567676e-01  2.06927519e-01]\n",
            " [-2.25153499e+00 -5.88970546e-01  1.13115191e+00  1.35077672e-01\n",
            "  -1.21226896e+00  6.90777273e-01 -4.79122945e-01  3.60050728e-01\n",
            "   3.76920114e-01 -1.11869560e+00]\n",
            " [ 7.89828035e-01 -1.00750880e+00 -1.30578587e+00 -8.82828988e-01\n",
            "  -3.46090034e-01  1.09403156e-01 -7.72583732e-01  7.44819312e-01\n",
            "   2.51464184e-01 -6.94798215e-01]\n",
            " [ 8.88992918e-01  1.16106836e+00 -9.86846968e-02 -2.14983045e-01\n",
            "  -1.77377135e+00 -4.07512592e-01 -2.91506713e-01  2.45379407e-01\n",
            "  -1.68426432e-01  2.44026938e-01]\n",
            " [ 1.53409029e+00 -5.29914099e-01 -4.90972283e-01 -1.30916531e+00\n",
            "  -8.66046674e-03  9.76812982e-01 -1.75107035e+00 -6.65856967e-01\n",
            "   3.59405025e-02  8.50102884e-01]\n",
            " [ 3.82870239e-01  3.25463628e-01 -2.24312786e-01  4.81874257e-01\n",
            "   1.01430388e+00 -1.70899178e+00  7.28535401e-01 -9.87598059e-02\n",
            "  -5.29988864e-01 -2.44307579e+00]\n",
            " [-1.38035132e+00  1.69805899e+00 -6.88548532e-01 -1.08476877e+00\n",
            "  -4.56425956e-01 -7.45147222e-01  1.24358633e-01  1.51697368e+00\n",
            "  -5.86615951e-01  1.54290051e-01]\n",
            " [-1.14723714e+00  1.52016644e+00  1.89043442e-01 -1.08181912e+00\n",
            "   9.04306220e-01  1.19998765e+00  1.61456363e-01 -1.63939697e+00\n",
            "   1.78516881e+00  3.10122521e-01]\n",
            " [ 1.17045430e+00 -5.50893205e-01 -3.98623925e-01  1.10453109e-01\n",
            "   1.11340168e+00  1.42990028e-01 -1.25683381e+00  2.61989197e-01\n",
            "   1.62953419e+00  6.58062825e-02]\n",
            " [ 1.29385524e-01 -1.26254374e+00 -1.40298909e+00 -6.37692139e-01\n",
            "  -3.26517647e-01  1.04060735e-01  1.65956974e-01  1.60190765e+00\n",
            "   5.86874384e-02  1.06442269e+00]\n",
            " [-3.93293346e-02  1.44890361e+00 -1.87039748e+00 -5.98731767e-01\n",
            "   9.83033396e-01 -1.71596005e-01  9.31529613e-01  3.85066103e-01\n",
            "   9.45876984e-01  6.13067728e-01]\n",
            " [ 6.73648934e-01  1.49245539e+00  9.86474019e-01  9.93806707e-01\n",
            "   2.04187588e-02 -5.81850210e-01 -6.59560088e-01  7.50944597e-01\n",
            "  -2.43846056e+00 -1.30717819e+00]\n",
            " [-9.63253686e-01 -2.47621379e-01 -2.63143804e+00  1.25872130e+00\n",
            "   6.00175236e-01  1.98458240e+00  1.06221447e+00  1.03037933e+00\n",
            "   2.25067603e+00 -5.70958087e-01]\n",
            " [-1.50345840e+00 -2.32357396e-01 -8.24992054e-01 -2.56845361e-01\n",
            "  -1.05021899e+00  5.67880067e-01  5.12982850e-01 -2.69225906e-02\n",
            "   3.11581503e-01 -1.42050727e-01]\n",
            " [ 7.52033668e-01  6.96407495e-02 -2.65445625e-01  9.29584470e-01\n",
            "   1.26082127e+00  1.33745383e+00 -9.90274689e-01 -5.34447208e-01\n",
            "  -1.70149609e+00 -2.38565018e-01]\n",
            " [ 4.16123814e-01 -1.32801175e-01  1.93085087e+00 -4.05843375e-01\n",
            "  -1.08850856e+00  5.68504207e-01  1.49933828e-01  5.49642596e-01\n",
            "   3.03787931e-01  2.43765761e-01]\n",
            " [-2.12229888e+00 -7.26114028e-01 -5.90324918e-01 -3.47964338e-01\n",
            "  -4.48391638e-01  4.12818762e-01  6.00882509e-01 -1.13164093e+00\n",
            "   6.86804407e-01  5.85768139e-01]\n",
            " [ 4.65770066e-01 -1.41789449e+00  4.40582300e-01  8.25954195e-02\n",
            "   9.60880075e-01  1.78435680e+00  1.58806789e+00  1.12644172e-01\n",
            "  -1.87469173e-03  6.31948284e-01]\n",
            " [-1.11503995e+00 -1.45068314e+00 -4.72530592e-01  1.22056891e+00\n",
            "  -3.31128298e-01  1.50258091e+00 -2.78811288e+00 -1.58720643e+00\n",
            "  -1.23688733e-01  8.88194541e-01]\n",
            " [-6.96230987e-02 -9.56527445e-02 -1.21741495e-01 -1.76289773e+00\n",
            "   1.15806887e+00 -6.82764720e-01  1.08953266e+00 -7.05234180e-02\n",
            "   1.06816039e+00  3.43257981e-01]\n",
            " [-1.06674491e-01  2.26261647e-01 -1.47297761e+00  6.02932717e-03\n",
            "   1.71604032e+00  1.30819356e+00 -9.85023583e-01  5.05685851e-01\n",
            "   2.47979885e-01  8.17188280e-01]\n",
            " [ 9.41528855e-02 -2.33503993e-01  1.33063078e+00  2.16396568e-01\n",
            "   1.25546432e+00  9.74386203e-01 -3.24487242e-01 -1.67000274e-01\n",
            "   1.92983243e+00  1.91482325e-01]\n",
            " [-7.58628423e-01 -1.20004328e+00  9.74132435e-01  1.60293721e-01\n",
            "  -7.92091951e-01  6.74584831e-01  1.59748695e-01 -1.66047507e+00\n",
            "   5.88685555e-01  1.33319070e+00]\n",
            " [ 2.55985023e+00  3.49025641e-02  2.32649658e-01  1.60659681e+00\n",
            "   1.68722267e-01  2.75341863e-01 -6.30618391e-01 -1.39437511e+00\n",
            "   9.12687936e-01 -1.27357024e+00]\n",
            " [ 1.14065624e+00 -7.88165559e-01  2.65233958e-01 -3.72271731e-01\n",
            "   1.17460024e+00  3.00846402e-01  1.95909535e+00 -1.08367768e+00\n",
            "   4.13863082e-01  4.73418809e-02]\n",
            " [ 2.79943571e-01  1.59592117e+00  5.85318030e-01 -1.14752541e+00\n",
            "   5.33510818e-01 -4.15619376e-01 -4.73354970e-01  1.04585733e+00\n",
            "  -6.02339983e-01 -3.79730328e-01]\n",
            " [ 3.24072544e-02  9.46185897e-01  5.81589803e-01 -2.34414912e-01\n",
            "  -2.72176466e-01 -1.16012966e+00 -7.59835089e-01 -6.54381086e-01\n",
            "  -1.49290942e-01  1.98676304e+00]\n",
            " [-6.75469434e-01 -2.95829068e-01 -2.05239840e+00  6.00571094e-01\n",
            "  -1.57744879e+00 -9.06589522e-01  1.04233537e+00 -2.10492843e+00\n",
            "   9.59204124e-02  8.00929647e-01]\n",
            " [ 1.52544424e+00 -9.20093108e-01 -6.24024850e-01  1.80443632e+00\n",
            "  -2.50601446e-02 -7.36263934e-01 -7.17485837e-01 -9.72556324e-01\n",
            "  -4.39672205e-01  1.08822048e+00]\n",
            " [ 8.87766069e-01 -1.17427030e+00  2.14586075e-01 -4.02159735e-01\n",
            "   7.82440404e-01 -1.56359727e-01  3.71524682e-01 -1.58605207e-01\n",
            "  -2.18708593e+00  4.70024454e-02]\n",
            " [-1.27174695e+00  7.47128412e-01 -6.79827892e-01 -6.05012656e-01\n",
            "  -8.90282501e-03  5.77793954e-01 -1.69743818e-01  1.64218277e+00\n",
            "   1.64881786e+00  1.71546859e+00]\n",
            " [-2.34318725e-01 -1.48195846e+00  1.22007851e+00 -4.16345285e-01\n",
            "   3.81663120e-02  6.28320103e-01 -1.60443640e+00  1.62912121e+00\n",
            "   8.74962329e-01  3.52271582e-01]\n",
            " [ 8.90916750e-01  5.56952539e-01  1.16828116e-01 -3.07774322e-01\n",
            "  -7.39142274e-01  2.87214281e-01  3.61203060e-01  1.08319880e+00\n",
            "   2.00660009e-01 -8.53201516e-01]\n",
            " [-1.57623285e+00 -1.27562162e-01 -2.74583767e-02 -9.80915828e-02\n",
            "  -1.53051290e+00  1.07446514e+00  1.07262975e+00 -8.23285165e-01\n",
            "   8.05982112e-01  9.52830862e-01]\n",
            " [ 3.84470766e-02 -9.48498626e-01  1.61338154e+00  3.80921434e-01\n",
            "  -2.51037455e-01  7.72845396e-01  1.62220849e+00 -4.97160147e-01\n",
            "   6.91422545e-01  1.94316017e+00]\n",
            " [-1.11656483e+00 -5.49253589e-01 -5.97855081e-01 -1.58327137e-01\n",
            "  -2.09973736e-01  3.00795439e-01 -8.20375520e-01 -6.22663489e-01\n",
            "   3.01290484e-01  1.54911860e-01]\n",
            " [ 8.74079809e-01  4.09355025e-01  7.71846636e-01 -1.14295204e+00\n",
            "  -3.83416311e-01  1.84837995e+00  3.92078047e-01  7.47392962e-01\n",
            "   2.72734737e-01  4.25335857e-01]\n",
            " [-2.30904052e-01  3.57157922e+00 -3.96155922e-01 -3.83212177e-02\n",
            "  -2.42483633e+00  1.10626666e+00 -5.52252950e-01 -6.07941060e-02\n",
            "  -5.28040551e-01 -1.38682945e-01]\n",
            " [-2.84247098e-01 -4.30417758e-02 -5.28014827e-02 -1.54205311e-01\n",
            "  -1.67877227e-01  1.30851845e+00  8.81416920e-01  8.87442318e-01\n",
            "  -7.32448881e-01  1.25682083e+00]\n",
            " [ 1.13164451e+00 -5.53404329e-01  1.52385202e+00 -6.83225943e-01\n",
            "  -1.84203184e+00  1.10152599e+00 -1.19518780e-01  9.76921565e-01\n",
            "  -7.54202163e-01 -1.26177001e+00]\n",
            " [ 1.23187179e+00 -1.40726856e+00 -1.56103051e+00 -1.92558689e+00\n",
            "  -2.79447230e+00 -1.03910438e+00 -2.16940796e+00 -3.56054846e-02\n",
            "  -2.23641735e+00 -1.09427342e+00]\n",
            " [ 2.33206200e+00  3.45124241e-01  5.28056754e-02 -1.62075198e+00\n",
            "  -2.45597666e-01  4.81085631e-02 -1.60518080e+00  1.26180681e-01\n",
            "   1.19123246e+00 -3.48258119e-01]\n",
            " [-1.97236368e-01 -2.04209642e+00 -1.39923387e+00  1.05769510e+00\n",
            "  -6.61550647e-01 -9.29711634e-01 -6.92583116e-01 -5.74661270e-02\n",
            "  -1.15841591e+00  1.26516506e-01]\n",
            " [-1.36000768e+00  7.74000002e-01 -1.05705578e+00  1.32026832e+00\n",
            "  -1.00326528e-02 -8.45644428e-01  9.11460610e-01 -1.37449688e+00\n",
            "  -5.47065645e-01 -7.55266106e-05]\n",
            " [-1.21166803e-01 -2.00858547e+00 -9.20646543e-01  1.68234342e-01\n",
            "  -1.31989156e+00  1.26642930e+00  4.95180889e-01 -5.14240391e-01\n",
            "  -2.20292465e-01  1.86156412e+00]\n",
            " [ 9.35988451e-01  3.80219145e-01 -1.41551877e+00  1.62961132e+00\n",
            "   1.05240107e+00 -1.48405388e-01 -5.49698069e-01 -1.87903939e-01\n",
            "  -1.20193668e+00 -4.70785558e-01]\n",
            " [ 7.63160514e-01 -1.80762128e+00 -3.14074374e-01  1.13755973e-01\n",
            "   1.03568037e-01 -1.17893695e+00 -1.18215289e+00  1.08916538e+00\n",
            "  -1.22452909e+00  1.00865096e+00]\n",
            " [-4.82365315e-01  1.07979635e+00 -4.21078505e-01 -1.16647132e+00\n",
            "   8.56554856e-01 -1.73912222e-02  1.44857659e+00  8.92200085e-01\n",
            "  -2.29426629e-01 -4.49667602e-01]\n",
            " [ 2.33723433e-02  1.90210018e-01 -8.81748527e-01  8.41939573e-01\n",
            "  -3.97363492e-01 -4.23027745e-01 -5.40688337e-01  2.31017267e-01\n",
            "  -6.92052602e-01  1.34970110e-01]\n",
            " [ 2.76660307e+00 -5.36094601e-02 -4.34004738e-01 -1.66768923e+00\n",
            "   5.02219248e-02 -1.10923094e+00 -3.75558119e-01  1.51607594e-01\n",
            "  -1.73098945e+00  1.57462752e-01]\n",
            " [ 3.04515175e-01 -1.29710002e+00 -3.92309192e-01 -1.83066636e+00\n",
            "   1.57550094e+00  3.30563277e-01 -1.79588501e-01 -1.63435831e-01\n",
            "   1.13144361e+00 -9.41655519e-02]\n",
            " [ 3.30816771e-01  1.51862956e+00 -3.46167148e-01 -1.09263532e+00\n",
            "  -8.24500575e-01  1.42866383e+00  9.14283085e-02 -5.02331288e-01\n",
            "   9.73644380e-01  9.97957386e-01]\n",
            " [-4.75647768e-01 -9.71936837e-01 -1.57052860e+00 -1.79388892e+00\n",
            "  -2.64986452e-01 -8.93195947e-01  1.85847441e+00  5.85377547e-02\n",
            "  -1.94214954e+00  1.41872928e+00]\n",
            " [ 1.61710309e-01  7.04979480e-01  6.82034777e-01  2.96556567e-01\n",
            "   5.23342630e-01  2.38760672e-01 -1.10638591e+00  3.66732198e-01\n",
            "   1.02390550e+00 -2.10056413e-01]\n",
            " [ 5.51302218e-01  4.19589145e-01  1.81565206e+00 -2.52750301e-01\n",
            "  -2.92004163e-01 -1.16931740e-01 -1.02391075e-01 -2.27261771e+00\n",
            "  -6.42609841e-01  2.99885067e-01]\n",
            " [-8.25651467e-03 -7.99339154e-01 -6.64779252e-01 -3.55613128e-01\n",
            "  -8.01571781e-01 -5.13050610e-01 -5.39390119e-01  8.95370847e-01\n",
            "   1.01639127e+00  9.33585094e-01]\n",
            " [ 4.26701799e-01 -7.08322484e-01  9.59830450e-01 -3.14250587e-01\n",
            "   2.30522083e-02  1.33822053e+00  8.39928561e-02  2.47284030e-01\n",
            "  -1.41277949e+00  4.87009294e-01]\n",
            " [-9.80006647e-01  1.01193966e+00 -1.84599177e-01 -2.23616884e+00\n",
            "  -3.58020103e-01 -2.28034538e-01  4.85475226e-01  6.70512391e-01\n",
            "  -3.27764245e-01  1.01286819e+00]\n",
            " [-3.16705533e+00 -7.13988998e-01 -1.11236427e+00 -1.25418351e+00\n",
            "   9.59706371e-01  8.29170399e-01 -7.75770020e-01  1.17805700e+00\n",
            "   1.01466892e-01 -4.21684101e-01]\n",
            " [-6.92922796e-01 -7.78271726e-01  4.72774857e-01  6.50154901e-01\n",
            "   2.38501212e-01 -2.05021768e+00  2.96358656e-01  5.65396564e-01\n",
            "  -6.69205605e-01  4.32505429e-02]\n",
            " [-1.86388430e+00 -1.22996906e+00 -3.24235348e-01 -3.09751144e-01\n",
            "   3.51679372e-01 -1.18692539e+00 -3.41206065e-01 -4.89779780e-01\n",
            "   5.28010474e-01  1.42104277e+00]\n",
            " [ 1.72092032e+00 -1.56844005e+00 -4.80141918e-02 -1.11252931e+00\n",
            "  -6.47449515e-02  4.22919280e-01  8.14908987e-02 -4.90116988e-02\n",
            "   1.48303917e+00  7.20989392e-01]\n",
            " [-2.72654462e-01  2.42113609e-02  8.70897807e-01  6.09790506e-01\n",
            "  -4.25076104e-01 -1.77524284e+00 -1.18465749e+00  1.45979225e-01\n",
            "  -1.78652685e+00 -1.52394498e-01]\n",
            " [-4.53569176e-01  9.99252803e-01 -1.31804382e+00 -1.93176898e+00\n",
            "  -4.19640742e-01  6.34763132e-01  1.06991860e+00 -9.09327017e-01\n",
            "   4.70263748e-01 -1.11143045e+00]]\n",
            "Augmented: [[-1.09008559e+00  9.95178350e-01  2.83290983e-01 -1.50490501e+00\n",
            "  -5.75052581e-01  1.65715943e+00 -2.42162420e+00 -4.29281831e-01\n",
            "   1.27528995e+00 -8.63158137e-01]\n",
            " [-6.83341137e-01 -9.68760660e-02  1.49170211e+00 -6.37512297e-01\n",
            "  -4.40434288e-01 -4.28628387e-01  2.21098513e+00  2.18641689e+00\n",
            "   1.01340759e+00  3.89768665e-01]\n",
            " [ 7.32913590e-01  1.48856493e+00 -9.35521384e-01  1.17721874e+00\n",
            "  -1.25033300e+00 -6.32028614e-01  9.12160239e-01 -1.42904990e+00\n",
            "  -1.30715033e-01 -8.58172631e-01]\n",
            " [-2.60074356e-01 -2.80075620e+00 -1.77122062e+00 -6.98487535e-01\n",
            "   9.31010103e-01 -1.67912794e-01  7.90095866e-03  6.87853509e-01\n",
            "  -8.70182656e-01  2.87209589e-01]\n",
            " [-8.09821504e-01 -1.72983659e+00 -3.90587309e-01  5.75195562e-01\n",
            "   3.42136722e-01 -6.10760577e-03  2.39742031e+00  4.12542958e-01\n",
            "   9.88089693e-01  2.24172560e+00]\n",
            " [-1.29854031e+00 -1.04095531e+00  1.74402471e+00 -7.96673035e-01\n",
            "   3.32309017e-02  1.07503886e+00  8.95761434e-01  1.75451698e+00\n",
            "   1.50499782e+00  1.07297494e+00]\n",
            " [-7.77163700e-01  7.92695571e-01  3.14584479e-01 -1.32487576e+00\n",
            "   1.42084672e+00  8.12959423e-01  5.05451234e-02 -2.33461263e-01\n",
            "  -1.18894746e+00  2.03106339e-01]\n",
            " [ 4.63984134e-01 -8.33322081e-01  1.16251653e+00 -1.09581335e+00\n",
            "  -2.11955268e+00  1.04544998e+00 -3.98310995e-01 -1.26398787e-01\n",
            "  -8.28163036e-01 -1.60238050e+00]\n",
            " [ 1.25078239e+00 -6.91036081e-01  1.66126497e+00  8.08697886e-01\n",
            "  -3.11210475e-01 -1.08017951e+00 -7.27406944e-01 -1.21289233e+00\n",
            "   2.09646705e+00  1.68023496e-01]\n",
            " [ 1.14575056e+00 -1.26951915e+00  1.81347614e-01  1.17925164e+00\n",
            "  -3.31463091e-01  1.03683735e+00 -1.07951287e+00 -1.36384075e+00\n",
            "   3.88754299e-01 -3.75594169e-01]\n",
            " [ 6.37599704e-01 -1.98005503e+00  7.12577120e-01  2.59969363e+00\n",
            "  -2.10783100e-02  3.98650176e-02  1.84604527e-01 -1.86234491e+00\n",
            "   4.35500327e-01 -1.60182748e+00]\n",
            " [-4.32134584e-01  1.24070245e+00 -7.34904472e-01  5.02638689e-01\n",
            "   1.01628673e+00  2.84463745e-01 -1.36589343e+00 -3.32844477e-01\n",
            "   1.96876503e+00 -2.02146350e+00]\n",
            " [-2.80240999e-01 -5.54275169e-01  1.21059848e-01  7.49605317e-01\n",
            "   1.61223864e+00 -2.64509503e-01  8.17396373e-01  4.99370943e-01\n",
            "   4.83700985e-01 -5.60341666e-01]\n",
            " [-1.00177645e+00 -1.10221021e+00 -7.56124725e-01  3.23076276e-01\n",
            "   7.64497065e-01  3.29191737e-01 -5.43900053e-01  1.80560091e+00\n",
            "   1.52821931e+00 -3.50417847e-01]\n",
            " [-8.27886391e-01  1.28047857e-01  1.26761113e+00  3.34154677e-01\n",
            "   5.60096376e-01 -2.06357234e-01  4.61325938e-01  1.54417525e+00\n",
            "  -2.30315094e-01  1.46889998e-01]\n",
            " [ 2.49361491e-01  2.81558259e-01 -1.41157639e+00 -1.87547896e+00\n",
            "  -1.01610740e+00  1.73665184e-01  5.58911209e-01 -5.31043762e-01\n",
            "   1.38661117e+00 -1.39593709e-01]\n",
            " [ 1.58610127e-02 -1.96130968e-01  1.34339277e-01  7.05863774e-01\n",
            "   6.69201109e-01 -8.92700052e-01  1.52871882e+00 -1.09539566e+00\n",
            "   8.85807013e-02 -2.70814308e-01]\n",
            " [-1.05344666e+00 -7.72876850e-02 -7.40501289e-01  7.42969431e-02\n",
            "   4.06633633e-01  1.47765226e+00  3.12439261e-01 -6.11594542e-01\n",
            "  -3.82266124e-01  1.43560371e-01]\n",
            " [ 8.90058440e-02  1.45742217e+00  1.39566541e+00 -3.57546226e-01\n",
            "  -5.45094457e-01 -2.55133172e+00 -5.43865371e-01 -9.78426908e-01\n",
            "  -3.45470771e-01  3.95166508e-01]\n",
            " [ 1.72737344e-01 -3.21351041e-02  1.99894596e-01 -1.24728073e-01\n",
            "   2.00566604e-01 -3.22533212e+00 -2.64238447e-01 -1.11219923e-01\n",
            "  -3.31908029e-01 -2.14363997e-01]\n",
            " [ 6.98855132e-01 -6.00272428e-01  2.20101458e+00  6.89686630e-01\n",
            "  -2.75957953e-03 -2.00939414e-01 -8.14672436e-02 -9.15676272e-01\n",
            "  -8.58488521e-02  2.82265782e-01]\n",
            " [ 5.75086630e-01  5.77522682e-01 -2.74565062e-01 -1.41469255e+00\n",
            "  -6.65554955e-01  1.61791593e+00  9.01113356e-01  3.69250384e-01\n",
            "  -7.51940558e-01  7.22742030e-03]\n",
            " [-1.26012367e+00 -5.54103973e-01 -2.44890857e-01 -3.60250232e-01\n",
            "   9.60149602e-01 -1.41300303e+00 -8.60377229e-01 -1.37505717e+00\n",
            "  -1.22799953e+00  1.27638162e-01]\n",
            " [-1.60489552e+00  7.51701682e-01 -2.46503292e-01  7.01780324e-02\n",
            "   3.26124409e-01 -4.28443632e-01  1.03753476e+00 -1.94711929e-01\n",
            "   6.03423942e-01 -1.95530117e-01]\n",
            " [ 2.86419402e-01  2.77495573e-01  2.50282424e-01 -9.72918150e-01\n",
            "   4.39423442e-01 -3.13234100e-01  6.35543073e-01 -2.15286265e+00\n",
            "  -1.45576253e+00  3.67027827e-01]\n",
            " [ 1.85847260e+00  8.32891650e-01 -6.82138450e-01 -1.69066272e+00\n",
            "   7.46233893e-01 -7.48603333e-02  5.95759261e-01  1.14929520e-01\n",
            "   3.89966123e-02  2.96220771e+00]\n",
            " [-1.05849466e-02 -1.61412306e-01 -1.21136191e-01 -5.82147017e-01\n",
            "   9.93680566e-01 -3.48031445e-01  6.40997748e-01  2.84233828e-01\n",
            "   1.22833955e+00  4.23761862e-01]\n",
            " [-1.21783977e+00 -1.32865488e+00  1.40868163e+00 -6.07321103e-01\n",
            "  -1.31705491e+00 -6.63895711e-01  1.26968033e+00 -1.42058220e+00\n",
            "  -8.57141517e-01 -6.63225243e-01]\n",
            " [-1.25564486e+00 -1.18649444e+00 -1.51779549e+00 -4.59797713e-01\n",
            "  -3.51361160e-01 -6.76815265e-01 -1.64864280e+00  1.25296674e+00\n",
            "  -1.31972514e+00  2.81615977e-01]\n",
            " [-1.07922158e+00  6.66149770e-01  9.56144840e-01 -8.76223887e-01\n",
            "  -1.92016806e+00  7.01510208e-01  1.88085559e+00  4.15325338e-01\n",
            "   1.69898109e-01  8.23342875e-01]\n",
            " [ 7.60599860e-01 -8.31155931e-01 -6.58838826e-01  6.12513250e-01\n",
            "  -1.40465676e-01  1.32232848e+00 -6.99287104e-01  7.50240715e-01\n",
            "   3.51991669e-01 -1.22855298e-01]\n",
            " [ 1.17145579e+00  6.77904436e-01 -1.00465467e+00  6.41608380e-01\n",
            "   1.37853830e+00 -1.24721800e-01 -2.43600808e-01 -6.70016350e-01\n",
            "  -4.25019848e-03  6.89782951e-01]\n",
            " [-8.22123285e-01 -1.34852466e+00 -3.75437426e-01 -1.37833528e+00\n",
            "   5.26766113e-01 -4.20966881e-01 -1.75034680e+00 -3.48976717e-01\n",
            "  -1.83261299e-01  4.52717879e-01]\n",
            " [-1.49818529e-01  1.86655936e+00 -5.18391367e-01 -6.10088487e-02\n",
            "  -9.93629429e-02 -2.76905496e-01  1.47480628e-01  5.40862095e-01\n",
            "   1.34945239e+00 -1.56567386e+00]\n",
            " [-5.14797859e-01 -4.49938522e-01  9.38162782e-01 -3.55273361e-01\n",
            "  -1.89162792e+00  9.34533526e-02 -2.86341888e-02  1.79382364e-01\n",
            "  -1.03080919e+00  1.72261695e+00]\n",
            " [-3.28314769e-01 -1.90463956e-01 -8.99696085e-01 -9.29612304e-01\n",
            "  -1.21918929e+00 -3.87587963e-01 -9.52526796e-01  2.05609814e+00\n",
            "  -1.87913869e+00 -1.12474828e+00]\n",
            " [-4.05869414e-01  6.71324181e-01 -4.13444397e-01  6.77353093e-01\n",
            "  -9.83256218e-01  6.50140226e-02  1.74909613e+00 -9.68113598e-01\n",
            "   4.28921363e-01  2.10509785e-01]\n",
            " [-2.25598997e+00 -5.91137644e-01  1.13146439e+00  1.36467372e-01\n",
            "  -1.20872129e+00  6.96500162e-01 -4.74067903e-01  3.59681526e-01\n",
            "   3.86273802e-01 -1.11511334e+00]\n",
            " [ 7.85373049e-01 -1.00967590e+00 -1.30547338e+00 -8.81439288e-01\n",
            "  -3.42542362e-01  1.15126045e-01 -7.67528690e-01  7.44450110e-01\n",
            "   2.60817871e-01 -6.91215950e-01]\n",
            " [ 8.84537932e-01  1.15890126e+00 -9.83722123e-02 -2.13593345e-01\n",
            "  -1.77022368e+00 -4.01789704e-01 -2.86451670e-01  2.45010205e-01\n",
            "  -1.59072744e-01  2.47609203e-01]\n",
            " [ 1.52963530e+00 -5.32081196e-01 -4.90659798e-01 -1.30777561e+00\n",
            "  -5.11279535e-03  9.82535871e-01 -1.74601531e+00 -6.66226169e-01\n",
            "   4.52941897e-02  8.53685149e-01]\n",
            " [ 3.78415254e-01  3.23296531e-01 -2.24000301e-01  4.83263957e-01\n",
            "   1.01785155e+00 -1.70326889e+00  7.33590444e-01 -9.91290078e-02\n",
            "  -5.20635177e-01 -2.43949352e+00]\n",
            " [-1.38480631e+00  1.69589190e+00 -6.88236048e-01 -1.08337907e+00\n",
            "  -4.52878285e-01 -7.39424333e-01  1.29413675e-01  1.51660448e+00\n",
            "  -5.77262264e-01  1.57872316e-01]\n",
            " [-1.15169213e+00  1.51799935e+00  1.89355927e-01 -1.08042942e+00\n",
            "   9.07853892e-01  1.20571054e+00  1.66511406e-01 -1.63976617e+00\n",
            "   1.79452250e+00  3.13704786e-01]\n",
            " [ 1.16599931e+00 -5.53060302e-01 -3.98311440e-01  1.11842809e-01\n",
            "   1.11694935e+00  1.48712917e-01 -1.25177877e+00  2.61619995e-01\n",
            "   1.63888788e+00  6.93885478e-02]\n",
            " [ 1.24930538e-01 -1.26471084e+00 -1.40267660e+00 -6.36302439e-01\n",
            "  -3.22969975e-01  1.09783624e-01  1.71012017e-01  1.60153845e+00\n",
            "   6.80411256e-02  1.06800495e+00]\n",
            " [-4.37843202e-02  1.44673651e+00 -1.87008499e+00 -5.97342067e-01\n",
            "   9.86581068e-01 -1.65873117e-01  9.36584656e-01  3.84696901e-01\n",
            "   9.55230671e-01  6.16649993e-01]\n",
            " [ 6.69193948e-01  1.49028829e+00  9.86786503e-01  9.95196407e-01\n",
            "   2.39664302e-02 -5.76127321e-01 -6.54505046e-01  7.50575395e-01\n",
            "  -2.42910688e+00 -1.30359592e+00]\n",
            " [-9.67708671e-01 -2.49788476e-01 -2.63112555e+00  1.26011100e+00\n",
            "   6.03722908e-01  1.99030529e+00  1.06726951e+00  1.03001013e+00\n",
            "   2.26002972e+00 -5.67375822e-01]\n",
            " [-1.50791338e+00 -2.34524494e-01 -8.24679569e-01 -2.55455661e-01\n",
            "  -1.04667132e+00  5.73602956e-01  5.18037892e-01 -2.72917925e-02\n",
            "   3.20935191e-01 -1.38468462e-01]\n",
            " [ 7.47578683e-01  6.74736524e-02 -2.65133140e-01  9.30974170e-01\n",
            "   1.26436894e+00  1.34317671e+00 -9.85219647e-01 -5.34816410e-01\n",
            "  -1.69214241e+00 -2.34982753e-01]\n",
            " [ 4.11668829e-01 -1.34968272e-01  1.93116335e+00 -4.04453675e-01\n",
            "  -1.08496088e+00  5.74227095e-01  1.54988871e-01  5.49273394e-01\n",
            "   3.13141618e-01  2.47348026e-01]\n",
            " [-2.12675387e+00 -7.28281125e-01 -5.90012433e-01 -3.46574638e-01\n",
            "  -4.44843967e-01  4.18541650e-01  6.05937551e-01 -1.13201013e+00\n",
            "   6.96158094e-01  5.89350404e-01]\n",
            " [ 4.61315081e-01 -1.42006159e+00  4.40894785e-01  8.39851194e-02\n",
            "   9.64427747e-01  1.79007968e+00  1.59312293e+00  1.12274970e-01\n",
            "   7.47899547e-03  6.35530549e-01]\n",
            " [-1.11949494e+00 -1.45285024e+00 -4.72218108e-01  1.22195861e+00\n",
            "  -3.27580627e-01  1.50830379e+00 -2.78305784e+00 -1.58757563e+00\n",
            "  -1.14335046e-01  8.91776807e-01]\n",
            " [-7.40780842e-02 -9.78198416e-02 -1.21429011e-01 -1.76150803e+00\n",
            "   1.16161655e+00 -6.77041831e-01  1.09458770e+00 -7.08926199e-02\n",
            "   1.07751407e+00  3.46840246e-01]\n",
            " [-1.11129476e-01  2.24094550e-01 -1.47266512e+00  7.41902703e-03\n",
            "   1.71958799e+00  1.31391645e+00 -9.79968540e-01  5.05316649e-01\n",
            "   2.57333572e-01  8.20770545e-01]\n",
            " [ 8.96979000e-02 -2.35671090e-01  1.33094326e+00  2.17786268e-01\n",
            "   1.25901199e+00  9.80109092e-01 -3.19432199e-01 -1.67369476e-01\n",
            "   1.93918612e+00  1.95064591e-01]\n",
            " [-7.63083409e-01 -1.20221038e+00  9.74444920e-01  1.61683421e-01\n",
            "  -7.88544279e-01  6.80307720e-01  1.64803738e-01 -1.66084427e+00\n",
            "   5.98039242e-01  1.33677297e+00]\n",
            " [ 2.55539525e+00  3.27354670e-02  2.32962143e-01  1.60798651e+00\n",
            "   1.72269938e-01  2.81064752e-01 -6.25563349e-01 -1.39474431e+00\n",
            "   9.22041623e-01 -1.26998797e+00]\n",
            " [ 1.13620126e+00 -7.90332656e-01  2.65546443e-01 -3.70882031e-01\n",
            "   1.17814791e+00  3.06569291e-01  1.96415040e+00 -1.08404688e+00\n",
            "   4.23216769e-01  5.09241462e-02]\n",
            " [ 2.75488586e-01  1.59375407e+00  5.85630515e-01 -1.14613571e+00\n",
            "   5.37058490e-01 -4.09896487e-01 -4.68299927e-01  1.04548813e+00\n",
            "  -5.92986296e-01 -3.76148062e-01]\n",
            " [ 2.79522689e-02  9.44018800e-01  5.81902287e-01 -2.33025212e-01\n",
            "  -2.68628794e-01 -1.15440677e+00 -7.54780046e-01 -6.54750288e-01\n",
            "  -1.39937255e-01  1.99034530e+00]\n",
            " [-6.79924419e-01 -2.97996165e-01 -2.05208592e+00  6.01960794e-01\n",
            "  -1.57390112e+00 -9.00866633e-01  1.04739041e+00 -2.10529763e+00\n",
            "   1.05274100e-01  8.04511912e-01]\n",
            " [ 1.52098925e+00 -9.22260206e-01 -6.23712366e-01  1.80582602e+00\n",
            "  -2.15124732e-02 -7.30541046e-01 -7.12430795e-01 -9.72925526e-01\n",
            "  -4.30318518e-01  1.09180274e+00]\n",
            " [ 8.83311083e-01 -1.17643740e+00  2.14898559e-01 -4.00770035e-01\n",
            "   7.85988075e-01 -1.50636839e-01  3.76579725e-01 -1.58974409e-01\n",
            "  -2.17773224e+00  5.05847107e-02]\n",
            " [-1.27620194e+00  7.44961315e-01 -6.79515408e-01 -6.03622956e-01\n",
            "  -5.35515363e-03  5.83516843e-01 -1.64688775e-01  1.64181357e+00\n",
            "   1.65817155e+00  1.71905086e+00]\n",
            " [-2.38773710e-01 -1.48412555e+00  1.22039100e+00 -4.14955585e-01\n",
            "   4.17139834e-02  6.34042992e-01 -1.59938136e+00  1.62875200e+00\n",
            "   8.84316016e-01  3.55853847e-01]\n",
            " [ 8.86461765e-01  5.54785442e-01  1.17140600e-01 -3.06384622e-01\n",
            "  -7.35594603e-01  2.92937170e-01  3.66258103e-01  1.08282960e+00\n",
            "   2.10013696e-01 -8.49619250e-01]\n",
            " [-1.58068783e+00 -1.29729259e-01 -2.71458922e-02 -9.67018829e-02\n",
            "  -1.52696523e+00  1.08018803e+00  1.07768479e+00 -8.23654367e-01\n",
            "   8.15335799e-01  9.56413127e-01]\n",
            " [ 3.39920911e-02 -9.50665723e-01  1.61369402e+00  3.82311134e-01\n",
            "  -2.47489784e-01  7.78568284e-01  1.62726353e+00 -4.97529349e-01\n",
            "   7.00776232e-01  1.94674244e+00]\n",
            " [-1.12101982e+00 -5.51420686e-01 -5.97542596e-01 -1.56937437e-01\n",
            "  -2.06426064e-01  3.06518328e-01 -8.15320477e-01 -6.23032691e-01\n",
            "   3.10644171e-01  1.58494125e-01]\n",
            " [ 8.69624824e-01  4.07187928e-01  7.72159120e-01 -1.14156234e+00\n",
            "  -3.79868640e-01  1.85410284e+00  3.97133089e-01  7.47023760e-01\n",
            "   2.82088424e-01  4.28918122e-01]\n",
            " [-2.35359037e-01  3.56941212e+00 -3.95843438e-01 -3.69315179e-02\n",
            "  -2.42128865e+00  1.11198955e+00 -5.47197907e-01 -6.11633080e-02\n",
            "  -5.18686864e-01 -1.35100680e-01]\n",
            " [-2.88702084e-01 -4.52088728e-02 -5.24889981e-02 -1.52815612e-01\n",
            "  -1.64329555e-01  1.31424134e+00  8.86471963e-01  8.87073116e-01\n",
            "  -7.23095194e-01  1.26040310e+00]\n",
            " [ 1.12718952e+00 -5.55571426e-01  1.52416450e+00 -6.81836243e-01\n",
            "  -1.83848417e+00  1.10724887e+00 -1.14463738e-01  9.76552363e-01\n",
            "  -7.44848476e-01 -1.25818775e+00]\n",
            " [ 1.22741680e+00 -1.40943566e+00 -1.56071803e+00 -1.92419719e+00\n",
            "  -2.79092463e+00 -1.03338149e+00 -2.16435292e+00 -3.59746866e-02\n",
            "  -2.22706366e+00 -1.09069115e+00]\n",
            " [ 2.32760701e+00  3.42957144e-01  5.31181599e-02 -1.61936228e+00\n",
            "  -2.42049995e-01  5.38314518e-02 -1.60012575e+00  1.25811479e-01\n",
            "   1.20058614e+00 -3.44675854e-01]\n",
            " [-2.01691354e-01 -2.04426351e+00 -1.39892138e+00  1.05908480e+00\n",
            "  -6.58002975e-01 -9.23988746e-01 -6.87528073e-01 -5.78353290e-02\n",
            "  -1.14906222e+00  1.30098771e-01]\n",
            " [-1.36446266e+00  7.71832905e-01 -1.05674329e+00  1.32165802e+00\n",
            "  -6.48498137e-03 -8.39921540e-01  9.16515652e-01 -1.37486608e+00\n",
            "  -5.37711958e-01  3.50673872e-03]\n",
            " [-1.25621789e-01 -2.01075257e+00 -9.20334058e-01  1.69624042e-01\n",
            "  -1.31634389e+00  1.27215219e+00  5.00235932e-01 -5.14609593e-01\n",
            "  -2.10938778e-01  1.86514639e+00]\n",
            " [ 9.31533465e-01  3.78052048e-01 -1.41520629e+00  1.63100102e+00\n",
            "   1.05594874e+00 -1.42682499e-01 -5.44643026e-01 -1.88273141e-01\n",
            "  -1.19258299e+00 -4.67203292e-01]\n",
            " [ 7.58705529e-01 -1.80978837e+00 -3.13761890e-01  1.15145673e-01\n",
            "   1.07115709e-01 -1.17321407e+00 -1.17709785e+00  1.08879618e+00\n",
            "  -1.21517541e+00  1.01223322e+00]\n",
            " [-4.86820301e-01  1.07762925e+00 -4.20766021e-01 -1.16508162e+00\n",
            "   8.60102528e-01 -1.16683335e-02  1.45363163e+00  8.91830883e-01\n",
            "  -2.20072942e-01 -4.46085336e-01]\n",
            " [ 1.89173578e-02  1.88042921e-01 -8.81436042e-01  8.43329273e-01\n",
            "  -3.93815820e-01 -4.17304856e-01 -5.35633295e-01  2.30648065e-01\n",
            "  -6.82698915e-01  1.38552375e-01]\n",
            " [ 2.76214809e+00 -5.57765571e-02 -4.33692254e-01 -1.66629953e+00\n",
            "   5.37695962e-02 -1.10350805e+00 -3.70503076e-01  1.51238392e-01\n",
            "  -1.72163576e+00  1.61045018e-01]\n",
            " [ 3.00060190e-01 -1.29926712e+00 -3.91996708e-01 -1.82927666e+00\n",
            "   1.57904861e+00  3.36286165e-01 -1.74533458e-01 -1.63805033e-01\n",
            "   1.14079730e+00 -9.05832866e-02]\n",
            " [ 3.26361786e-01  1.51646246e+00 -3.45854663e-01 -1.09124562e+00\n",
            "  -8.20952903e-01  1.43438672e+00  9.64833513e-02 -5.02700490e-01\n",
            "   9.82998067e-01  1.00153965e+00]\n",
            " [-4.80102753e-01 -9.74103934e-01 -1.57021612e+00 -1.79249922e+00\n",
            "  -2.61438780e-01 -8.87473058e-01  1.86352945e+00  5.81685527e-02\n",
            "  -1.93279586e+00  1.42231154e+00]\n",
            " [ 1.57255324e-01  7.02812383e-01  6.82347261e-01  2.97946267e-01\n",
            "   5.26890302e-01  2.44483560e-01 -1.10133086e+00  3.66362996e-01\n",
            "   1.03325919e+00 -2.06474147e-01]\n",
            " [ 5.46847233e-01  4.17422048e-01  1.81596455e+00 -2.51360601e-01\n",
            "  -2.88456491e-01 -1.11208851e-01 -9.73360323e-02 -2.27298691e+00\n",
            "  -6.33256154e-01  3.03467332e-01]\n",
            " [-1.27115002e-02 -8.01506251e-01 -6.64466768e-01 -3.54223428e-01\n",
            "  -7.98024109e-01 -5.07327722e-01 -5.34335077e-01  8.95001645e-01\n",
            "   1.02574496e+00  9.37167360e-01]\n",
            " [ 4.22246814e-01 -7.10489581e-01  9.60142935e-01 -3.12860887e-01\n",
            "   2.65998796e-02  1.34394342e+00  8.90478989e-02  2.46914828e-01\n",
            "  -1.40342580e+00  4.90591559e-01]\n",
            " [-9.84461633e-01  1.00977256e+00 -1.84286693e-01 -2.23477914e+00\n",
            "  -3.54472431e-01 -2.22311650e-01  4.90530269e-01  6.70143189e-01\n",
            "  -3.18410558e-01  1.01645046e+00]\n",
            " [-3.17151031e+00 -7.16156095e-01 -1.11205179e+00 -1.25279381e+00\n",
            "   9.63254043e-01  8.34893288e-01 -7.70714978e-01  1.17768780e+00\n",
            "   1.10820580e-01 -4.18101835e-01]\n",
            " [-6.97377782e-01 -7.80438824e-01  4.73087342e-01  6.51544601e-01\n",
            "   2.42048884e-01 -2.04449479e+00  3.01413699e-01  5.65027362e-01\n",
            "  -6.59851918e-01  4.68328082e-02]\n",
            " [-1.86833928e+00 -1.23213616e+00 -3.23922864e-01 -3.08361444e-01\n",
            "   3.55227043e-01 -1.18120250e+00 -3.36151022e-01 -4.90148982e-01\n",
            "   5.37364161e-01  1.42462503e+00]\n",
            " [ 1.71646533e+00 -1.57060714e+00 -4.77017072e-02 -1.11113961e+00\n",
            "  -6.11972801e-02  4.28642168e-01  8.65459415e-02 -4.93809008e-02\n",
            "   1.49239286e+00  7.24571657e-01]\n",
            " [-2.77109447e-01  2.20442638e-02  8.71210291e-01  6.11180206e-01\n",
            "  -4.21528432e-01 -1.76951995e+00 -1.17960245e+00  1.45610023e-01\n",
            "  -1.77717317e+00 -1.48812233e-01]\n",
            " [-4.58024162e-01  9.97085706e-01 -1.31773134e+00 -1.93037928e+00\n",
            "  -4.16093070e-01  6.40486020e-01  1.07497364e+00 -9.09696219e-01\n",
            "   4.79617435e-01 -1.10784818e+00]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQop-rAuwnHo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(1234)\n",
        "from functools import reduce\n",
        "import math as m\n",
        "\n",
        "import scipy.io\n",
        "import theano\n",
        "import theano.tensor as T\n",
        "\n",
        "from scipy.interpolate import griddata\n",
        "from sklearn.preprocessing import scale\n",
        "\n",
        "import lasagne\n",
        "from lasagne.regularization import regularize_layer_params, regularize_network_params, l1, l2\n",
        "from lasagne.layers import Conv2DLayer, MaxPool2DLayer, InputLayer\n",
        "from lasagne.layers import DenseLayer, ElemwiseMergeLayer, FlattenLayer\n",
        "from lasagne.layers import ConcatLayer, ReshapeLayer, get_output_shape\n",
        "from lasagne.layers import Conv1DLayer, DimshuffleLayer, LSTMLayer, SliceLayer\n",
        "\n",
        "\n",
        "def azim_proj(pos):\n",
        "    \n",
        "    [r, elev, az] = cart2sph(pos[0], pos[1], pos[2])\n",
        "    return pol2cart(az, m.pi / 2 - elev)\n",
        "\n",
        "\n",
        "def gen_images(locs, features, n_gridpoints, normalize=True, augment=False, pca=False, std_mult=0.1, n_components=2, edgeless=False):\n",
        "    \n",
        "    feat_array_temp = []\n",
        "    nElectrodes = locs.shape[0]    \n",
        "\n",
        "    assert features.shape[1] % nElectrodes == 0\n",
        "    n_colors = features.shape[1]//nElectrodes\n",
        "    for c in range(n_colors):\n",
        "        feat_array_temp.append(features[:, c * nElectrodes : nElectrodes * (c+1)])\n",
        "    if augment:\n",
        "        if pca:\n",
        "            for c in range(n_colors):\n",
        "                feat_array_temp[c] = augment_EEG(feat_array_temp[c], std_mult, pca=True, n_components=n_components)\n",
        "        else:\n",
        "            for c in range(n_colors):\n",
        "                feat_array_temp[c] = augment_EEG(feat_array_temp[c], std_mult, pca=False, n_components=n_components)\n",
        "    n_samples = features.shape[0]\n",
        "\n",
        "    grid_x, grid_y = np.mgrid[min(locs[:, 0]):max(locs[:, 0]):n_gridpoints*1j, min(locs[:, 1]):max(locs[:, 1]):n_gridpoints*1j]\n",
        "    temp_interp = []\n",
        "    for c in range(n_colors):\n",
        "        temp_interp.append(np.zeros([n_samples, n_gridpoints, n_gridpoints]))\n",
        "\n",
        "    if edgeless:\n",
        "        min_x, min_y = np.min(locs, axis=0)\n",
        "        max_x, max_y = np.max(locs, axis=0)\n",
        "        locs = np.append(locs, np.array([[min_x, min_y], [min_x, max_y], [max_x, min_y], [max_x, max_y]]), axis=0)\n",
        "        for c in range(n_colors):\n",
        "            feat_array_temp[c] = np.append(feat_array_temp[c], np.zeros((n_samples, 4)), axis=1)\n",
        "\n",
        "    \n",
        "    for i in range(n_samples):\n",
        "        for c in range(n_colors):\n",
        "            temp_interp[c][i, :, :] = griddata(locs, feat_array_temp[c][i, :], (grid_x, grid_y),\n",
        "                                               method='cubic', fill_value=np.nan)\n",
        "        print('Interpolating {0}/{1}\\r'.format(i + 1, n_samples), end='\\r')\n",
        "\n",
        "    for c in range(n_colors):\n",
        "        if normalize:\n",
        "            temp_interp[c][~np.isnan(temp_interp[c])] = \\\n",
        "                scale(temp_interp[c][~np.isnan(temp_interp[c])])\n",
        "        temp_interp[c] = np.nan_to_num(temp_interp[c])\n",
        "    return np.swapaxes(np.asarray(temp_interp), 0, 1)     \n",
        "\n",
        "def build_cnn(input_var=None, w_init=None, n_layers=(4, 2, 1), n_filters_first=32, imsize=32, n_colors=3):\n",
        "    \n",
        "    weights = []        \n",
        "    count = 0\n",
        "    \n",
        "    if w_init is None:\n",
        "        w_init = [lasagne.init.GlorotUniform()] * sum(n_layers)\n",
        "    network = InputLayer(shape=(None, n_colors, imsize, imsize),\n",
        "                                        input_var=input_var)\n",
        "    for i, s in enumerate(n_layers):\n",
        "        for l in range(s):\n",
        "            network = Conv2DLayer(network, num_filters=n_filters_first * (2 ** i), filter_size=(3, 3),\n",
        "                          W=w_init[count], pad='same')\n",
        "            count += 1\n",
        "            weights.append(network.W)\n",
        "        network = MaxPool2DLayer(network, pool_size=(2, 2))\n",
        "    return network, weights\n",
        "\n",
        "\n",
        "def build_convpool_max(input_vars, nb_classes, imsize=32, n_colors=3, n_timewin=7):\n",
        "    convnets = []\n",
        "    w_init = None\n",
        "    \n",
        "    for i in range(n_timewin):\n",
        "        if i == 0:\n",
        "            convnet, w_init = build_cnn(input_vars[i], imsize=imsize, n_colors=n_colors)\n",
        "        else:\n",
        "            convnet, _ = build_cnn(input_vars[i], w_init=w_init, imsize=imsize, n_colors=n_colors)\n",
        "        convnets.append(convnet)\n",
        "    \n",
        "    convpool = ElemwiseMergeLayer(convnets, theano.tensor.maximum)\n",
        "    \n",
        "    convpool = DenseLayer(lasagne.layers.dropout(convpool, p=.5),\n",
        "            num_units=512, nonlinearity=lasagne.nonlinearities.rectify)\n",
        "    \n",
        "    convpool = lasagne.layers.DenseLayer(lasagne.layers.dropout(convpool, p=.5),\n",
        "            num_units=nb_classes, nonlinearity=lasagne.nonlinearities.softmax)\n",
        "    return convpool\n",
        "\n",
        "\n",
        "def build_convpool_conv1d(input_vars, nb_classes, imsize=32, n_colors=3, n_timewin=7):\n",
        "    \n",
        "    convnets = []\n",
        "    w_init = None\n",
        "    \n",
        "    for i in range(n_timewin):\n",
        "        if i == 0:\n",
        "            convnet, w_init = build_cnn(input_vars[i], imsize=imsize, n_colors=n_colors)\n",
        "        else:\n",
        "            convnet, _ = build_cnn(input_vars[i], w_init=w_init, imsize=imsize, n_colors=n_colors)\n",
        "        convnets.append(FlattenLayer(convnet))\n",
        "    convpool = ConcatLayer(convnets)\n",
        "    convpool = ReshapeLayer(convpool, ([0], n_timewin, get_output_shape(convnets[0])[1]))\n",
        "    convpool = DimshuffleLayer(convpool, (0, 2, 1))\n",
        "    convpool = Conv1DLayer(convpool, 64, 3)\n",
        "    convpool = DenseLayer(lasagne.layers.dropout(convpool, p=.5),\n",
        "            num_units=512, nonlinearity=lasagne.nonlinearities.rectify)\n",
        "    convpool = DenseLayer(lasagne.layers.dropout(convpool, p=.5),\n",
        "            num_units=nb_classes, nonlinearity=lasagne.nonlinearities.softmax)\n",
        "    return convpool\n",
        "\n",
        "\n",
        "def build_convpool_lstm(input_vars, nb_classes, grad_clip=110, imsize=32, n_colors=3, n_timewin=7):\n",
        "    \n",
        "    convnets = []\n",
        "    w_init = None\n",
        "    for i in range(n_timewin):\n",
        "        if i == 0:\n",
        "            convnet, w_init = build_cnn(input_vars[i], imsize=imsize, n_colors=n_colors)\n",
        "        else:\n",
        "            convnet, _ = build_cnn(input_vars[i], w_init=w_init, imsize=imsize, n_colors=n_colors)\n",
        "        convnets.append(FlattenLayer(convnet))\n",
        "    \n",
        "    convpool = ConcatLayer(convnets)\n",
        "    convpool = ReshapeLayer(convpool, ([0], n_timewin, get_output_shape(convnets[0])[1]))\n",
        "    convpool = LSTMLayer(convpool, num_units=128, grad_clipping=grad_clip,\n",
        "        nonlinearity=lasagne.nonlinearities.tanh)\n",
        "    \n",
        "    convpool = SliceLayer(convpool, -1, 1)     \n",
        "    convpool = DenseLayer(lasagne.layers.dropout(convpool, p=.5),\n",
        "            num_units=256, nonlinearity=lasagne.nonlinearities.rectify)\n",
        "    convpool = DenseLayer(lasagne.layers.dropout(convpool, p=.5),\n",
        "            num_units=nb_classes, nonlinearity=lasagne.nonlinearities.softmax)\n",
        "    return convpool\n",
        "\n",
        "\n",
        "def build_convpool_mix(input_vars, nb_classes, grad_clip=110, imsize=32, n_colors=3, n_timewin=7):\n",
        "    \n",
        "    convnets = []\n",
        "    w_init = None\n",
        "    for i in range(n_timewin):\n",
        "        if i == 0:\n",
        "            convnet, w_init = build_cnn(input_vars[i], imsize=imsize, n_colors=n_colors)\n",
        "        else:\n",
        "            convnet, _ = build_cnn(input_vars[i], w_init=w_init, imsize=imsize, n_colors=n_colors)\n",
        "        convnets.append(FlattenLayer(convnet))\n",
        "    convpool = ConcatLayer(convnets)\n",
        "    convpool = ReshapeLayer(convpool, ([0], n_timewin, get_output_shape(convnets[0])[1]))\n",
        "    reformConvpool = DimshuffleLayer(convpool, (0, 2, 1))\n",
        "    conv_out = Conv1DLayer(reformConvpool, 64, 3)\n",
        "    conv_out = FlattenLayer(conv_out)\n",
        "    lstm = LSTMLayer(convpool, num_units=128, grad_clipping=grad_clip,\n",
        "        nonlinearity=lasagne.nonlinearities.tanh)\n",
        "    lstm_out = SliceLayer(lstm, -1, 1)\n",
        "    dense_input = ConcatLayer([conv_out, lstm_out])\n",
        "    convpool = DenseLayer(lasagne.layers.dropout(dense_input, p=.5),\n",
        "            num_units=512, nonlinearity=lasagne.nonlinearities.rectify)\n",
        "    convpool = DenseLayer(convpool,\n",
        "            num_units=nb_classes, nonlinearity=lasagne.nonlinearities.softmax)\n",
        "    return convpool\n",
        "\n",
        "\n",
        "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
        "    \n",
        "    if inputs.ndim == 4:\n",
        "        input_len = inputs.shape[0]\n",
        "    elif inputs.ndim == 5:\n",
        "        input_len = inputs.shape[1]\n",
        "    assert input_len == len(targets)\n",
        "    if shuffle:\n",
        "        indices = np.arange(input_len)\n",
        "        np.random.shuffle(indices)\n",
        "    for start_idx in range(0, input_len, batchsize):\n",
        "        if shuffle:\n",
        "            excerpt = indices[start_idx:start_idx + batchsize]\n",
        "        else:\n",
        "            excerpt = slice(start_idx, start_idx + batchsize)\n",
        "        if inputs.ndim == 4:\n",
        "            yield inputs[excerpt], targets[excerpt]\n",
        "        elif inputs.ndim == 5:\n",
        "            yield inputs[:, excerpt], targets[excerpt]\n",
        "\n",
        "\n",
        "def train(images, labels, fold, model_type, batch_size=32, num_epochs=5):\n",
        "    \n",
        "    print('train')\n",
        "    num_classes = len(np.unique(labels))\n",
        "    (X_train, y_train), (X_val, y_val), (X_test, y_test) = reformatInput(images, labels, fold)\n",
        "    X_train = X_train.astype(\"float32\", casting='unsafe')\n",
        "    X_val = X_val.astype(\"float32\", casting='unsafe')\n",
        "    X_test = X_test.astype(\"float32\", casting='unsafe')\n",
        "    input_var = T.TensorType('floatX', ((False,) * 4))()\n",
        "    target_var = T.ivector('targets')\n",
        "    print(\"Building model and compiling functions...\")\n",
        "    if model_type == '1dconv':\n",
        "        network = build_convpool_conv1d(input_var, num_classes)\n",
        "    elif model_type == 'maxpool':\n",
        "        network = build_convpool_max(input_var, num_classes)\n",
        "    elif model_type == 'lstm':\n",
        "        network = build_convpool_lstm(input_var, num_classes, 100)\n",
        "    elif model_type == 'mix':\n",
        "        network = build_convpool_mix(input_var, num_classes, 100)\n",
        "    elif model_type == 'cnn':\n",
        "        input_var = T.tensor4('inputs')\n",
        "        network, _ = build_cnn(input_var)\n",
        "        network = DenseLayer(lasagne.layers.dropout(network, p=.5),\n",
        "                             num_units=256,\n",
        "                             nonlinearity=lasagne.nonlinearities.rectify)\n",
        "        network = DenseLayer(lasagne.layers.dropout(network, p=.5),\n",
        "                             num_units=num_classes,\n",
        "                             nonlinearity=lasagne.nonlinearities.softmax)\n",
        "    else:\n",
        "        raise ValueError(\"Model not supported ['1dconv', 'maxpool', 'lstm', 'mix', 'cnn']\")\n",
        "  \n",
        "    prediction = lasagne.layers.get_output(network)\n",
        "    loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
        "    loss = loss.mean()\n",
        "    reg_factor = 1e-4\n",
        "    l2_penalty = regularize_network_params(network, l2) * reg_factor\n",
        "    loss += l2_penalty\n",
        "\n",
        "    params = lasagne.layers.get_all_params(network, trainable=True)\n",
        "    updates = lasagne.updates.adam(loss, params, learning_rate=0.001)\n",
        "\n",
        "    test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
        "    test_loss = lasagne.objectives.categorical_crossentropy(test_prediction,\n",
        "                                                            target_var)\n",
        "    test_loss = test_loss.mean()\n",
        "    \n",
        "    test_acc = T.mean(T.eq(T.argmax(test_prediction, axis=1), target_var),\n",
        "                      dtype=theano.config.floatX)\n",
        " \n",
        "    train_fn = theano.function([input_var, target_var], loss, updates=updates)\n",
        "    val_fn = theano.function([input_var, target_var], [test_loss, test_acc])\n",
        "    print(\"Starting training...\")\n",
        "    best_validation_accu = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        train_err = 0\n",
        "        train_batches = 0\n",
        "        start_time = time.time()\n",
        "        print(9)\n",
        "        for batch in iterate_minibatches(X_train, y_train, batch_size, shuffle=False):\n",
        "            inputs, targets = batch\n",
        "\n",
        "            inputs1=inputs\n",
        "            inputs=inputs1[1,:,:,:,:]\n",
        "            train_err += train_fn(inputs, targets)\n",
        "            \n",
        "            \n",
        "            inputs=inputs1[2,:,:,:,:]\n",
        "            train_err += train_fn(inputs, targets)\n",
        "\n",
        "            \n",
        "            inputs=inputs1[3,:,:,:,:]\n",
        "            train_err += train_fn(inputs, targets)\n",
        "\n",
        "            \n",
        "            inputs=inputs1[4,:,:,:,:]\n",
        "            train_err += train_fn(inputs, targets)\n",
        "\n",
        "            \n",
        "            inputs=inputs1[5,:,:,:,:]\n",
        "            train_err += train_fn(inputs, targets)\n",
        "\n",
        "            \n",
        "            inputs=inputs1[6,:,:,:,:]\n",
        "            train_err += train_fn(inputs, targets)\n",
        "\n",
        "            \n",
        "            inputs=inputs1[0,:,:,:,:]\n",
        "            train_err += train_fn(inputs, targets)\n",
        "\n",
        "            train_batches += 1\n",
        "        val_err = 0\n",
        "        print('01')\n",
        "\n",
        "        val_acc = 0\n",
        "        val_batches = 0\n",
        "        for batch in iterate_minibatches(X_val, y_val, batch_size, shuffle=False):\n",
        "            inputs, targets = batch\n",
        "            \n",
        "            inputs1=inputs\n",
        "            inputs=inputs1[1,:,:,:,:]\n",
        "            err, acc = val_fn(inputs, targets)\n",
        "            val_err += err\n",
        "            val_acc += acc\n",
        "\n",
        "            \n",
        "            inputs=inputs1[2,:,:,:,:]\n",
        "            err, acc = val_fn(inputs, targets)\n",
        "            val_err += err\n",
        "            val_acc += acc\n",
        "\n",
        "            inputs=inputs1[3,:,:,:,:]\n",
        "            err, acc = val_fn(inputs, targets)\n",
        "            val_err += err\n",
        "            val_acc += acc\n",
        "\n",
        "            inputs=inputs1[4,:,:,:,:]\n",
        "            err, acc = val_fn(inputs, targets)\n",
        "            val_err += err\n",
        "            val_acc += acc\n",
        "\n",
        "            inputs=inputs1[5,:,:,:,:]\n",
        "            err, acc = val_fn(inputs, targets)\n",
        "            val_err += err\n",
        "            val_acc += acc\n",
        "\n",
        "            inputs=inputs1[6,:,:,:,:]\n",
        "            err, acc = val_fn(inputs, targets)\n",
        "            val_err += err\n",
        "            val_acc += acc\n",
        "\n",
        "            inputs=inputs1[0,:,:,:,:]\n",
        "            err, acc = val_fn(inputs, targets)\n",
        "            val_err += err\n",
        "            val_acc += acc\n",
        "            \n",
        "            val_batches += 1\n",
        "\n",
        "        av_train_err = train_err / train_batches\n",
        "        av_train_err = av_train_err / 7\n",
        "\n",
        "        av_val_err = val_err / val_batches\n",
        "        av_val_acc = val_acc / val_batches\n",
        "\n",
        "        av_val_err = av_val_err / 7\n",
        "        av_val_acc = av_val_acc / 7\n",
        "        print(\"Epoch {} of {} took {:.3f}s\".format(\n",
        "            epoch + 1, num_epochs, time.time() - start_time))\n",
        "        print(\"  training loss:\\t\\t{:.6f}\".format(av_train_err))\n",
        "        print(\"  validation loss:\\t\\t{:.6f}\".format(av_val_err))\n",
        "        print(\"  validation accuracy:\\t\\t{:.2f} %\".format(av_val_acc * 100))\n",
        "        if av_val_acc > best_validation_accu:\n",
        "            best_validation_accu = av_val_acc\n",
        "            test_err = 0\n",
        "            print('00')\n",
        "            test_acc = 0\n",
        "            test_batches = 0\n",
        "            for batch in iterate_minibatches(X_test, y_test, batch_size, shuffle=False):\n",
        "                inputs, targets = batch\n",
        "                \n",
        "                inputs1=inputs\n",
        "                inputs=inputs1[1,:,:,:,:]\n",
        "                err, acc = val_fn(inputs, targets)\n",
        "                test_err += err\n",
        "                test_acc += acc\n",
        "\n",
        "                inputs=inputs1[2,:,:,:,:]\n",
        "                err, acc = val_fn(inputs, targets)\n",
        "                test_err += err\n",
        "                test_acc += acc\n",
        "                \n",
        "                inputs=inputs1[3,:,:,:,:]\n",
        "                err, acc = val_fn(inputs, targets)\n",
        "                test_err += err\n",
        "                test_acc += acc\n",
        "\n",
        "                inputs=inputs1[4,:,:,:,:]\n",
        "                err, acc = val_fn(inputs, targets)\n",
        "                test_err += err\n",
        "                test_acc += acc\n",
        "\n",
        "                inputs=inputs1[5,:,:,:,:]\n",
        "                err, acc = val_fn(inputs, targets)\n",
        "                test_err += err\n",
        "                test_acc += acc\n",
        "\n",
        "                inputs=inputs1[6,:,:,:,:]\n",
        "                err, acc = val_fn(inputs, targets)\n",
        "                test_err += err\n",
        "                test_acc += acc\n",
        "\n",
        "                inputs=inputs1[0,:,:,:,:]\n",
        "                err, acc = val_fn(inputs, targets)\n",
        "                test_err += err\n",
        "                test_acc += acc\n",
        "\n",
        "                test_batches += 1\n",
        "            av_test_err = test_err / test_batches\n",
        "            av_test_acc = test_acc / test_batches\n",
        "            \n",
        "            av_test_err = av_test_err / 7\n",
        "            av_test_acc = av_test_acc / 7\n",
        "            \n",
        "            print(\"Final results:\")\n",
        "            print(\"  test loss:\\t\\t\\t{:.6f}\".format(av_test_err))\n",
        "            print(\"  test accuracy:\\t\\t{:.2f} %\".format(av_test_acc * 100))\n",
        "            np.savez('weights_lasg_{0}'.format(model_type), *lasagne.layers.get_all_param_values(network))\n",
        "    print('-'*50)\n",
        "    print(\"Best validation accuracy:\\t\\t{:.2f} %\".format(best_validation_accu * 100))\n",
        "    print(\"Best test accuracy:\\t\\t{:.2f} %\".format(av_test_acc * 100))\n",
        "    return av_test_acc\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dPzXEyIHFNs",
        "colab_type": "code",
        "outputId": "37706e26-802d-4224-ce1e-f6a05154d6b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "if __name__ == '__main__':\n",
        "    \n",
        "\n",
        "    print('Loading data...')\n",
        "    locs = scipy.io.loadmat('/content/sample_data/Neuroscan_locs_orig.mat')\n",
        "    locs_3d = locs['A']\n",
        "    locs_2d = []\n",
        "    for e in locs_3d:\n",
        "        locs_2d.append(azim_proj(e))\n",
        "\n",
        "    feats = scipy.io.loadmat('/content/sample_data/FeatureMat_timeWin.mat')['features']\n",
        "    print(feats[:, -1])\n",
        "    b=np.squeeze(feats[:, -1])- 1\n",
        "    print(b.shape)\n",
        "    print(feats[:, -1].shape)\n",
        "    subj_nums = np.squeeze(scipy.io.loadmat('/content/sample_data/trials_subNums.mat')['subjectNum'])\n",
        "    fold_pairs = []\n",
        "    for i in np.unique(subj_nums):\n",
        "        ts = subj_nums == i               \n",
        "        tr = np.squeeze(np.nonzero(np.bitwise_not(ts))) \n",
        "        ts = np.squeeze(np.nonzero(ts))    \n",
        "        np.random.shuffle(tr)  \n",
        "        np.random.shuffle(ts)\n",
        "        fold_pairs.append((tr, ts))\n",
        "\n",
        "    \n",
        "    images_timewin = np.array([gen_images(np.array(locs_2d),\n",
        "                                          feats[:, i * 192:(i + 1) * 192], 32, normalize=True) for i in\n",
        "                               range(feats.shape[1]//192)\n",
        "                               ])\n",
        "    \n",
        "    print('\\n')\n",
        "    print('Training the LSTM-CONV Model...')\n",
        "    test_acc_mix = []\n",
        "    test_acc_cnn = []\n",
        "    for i in range(len(fold_pairs)):\n",
        "        print('fold {0}/{1}'.format(i+1, len(fold_pairs)))\n",
        "        \n",
        "        a=train(images_timewin,b,  fold_pairs[i], 'cnn')\n",
        "        \n",
        "        test_acc_cnn.append(a)\n",
        "    print('*' * 40)\n",
        "    print('Average MIX test accuracy: {0}'.format(np.mean(test_acc_mix)*100))\n",
        "    print('Average CNN test accuracy: {0}'.format(np.mean(test_acc_cnn) * 100))\n",
        "    print('*' * 40)\n",
        "\n",
        "    print('Done!')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "[1. 1. 1. ... 4. 4. 4.]\n",
            "(2670,)\n",
            "(2670,)\n",
            "\n",
            "\n",
            "Training the LSTM-CONV Model...\n",
            "fold 1/13\n",
            "train\n",
            "Building model and compiling functions...\n",
            "Starting training...\n",
            "9\n",
            "01\n",
            "Epoch 1 of 5 took 436.442s\n",
            "  training loss:\t\t0.817328\n",
            "  validation loss:\t\t0.378874\n",
            "  validation accuracy:\t\t87.80 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t1.763371\n",
            "  test accuracy:\t\t59.68 %\n",
            "9\n",
            "01\n",
            "Epoch 2 of 5 took 445.839s\n",
            "  training loss:\t\t0.374214\n",
            "  validation loss:\t\t0.206743\n",
            "  validation accuracy:\t\t91.85 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t1.451927\n",
            "  test accuracy:\t\t62.67 %\n",
            "9\n",
            "01\n",
            "Epoch 3 of 5 took 441.556s\n",
            "  training loss:\t\t0.286212\n",
            "  validation loss:\t\t0.161100\n",
            "  validation accuracy:\t\t91.96 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t1.258592\n",
            "  test accuracy:\t\t61.11 %\n",
            "9\n",
            "01\n",
            "Epoch 4 of 5 took 435.177s\n",
            "  training loss:\t\t0.252533\n",
            "  validation loss:\t\t0.145060\n",
            "  validation accuracy:\t\t92.73 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t1.472711\n",
            "  test accuracy:\t\t64.63 %\n",
            "9\n",
            "01\n",
            "Epoch 5 of 5 took 438.288s\n",
            "  training loss:\t\t0.239961\n",
            "  validation loss:\t\t0.165819\n",
            "  validation accuracy:\t\t92.15 %\n",
            "--------------------------------------------------\n",
            "Best validation accuracy:\t\t92.73 %\n",
            "Best test accuracy:\t\t64.63 %\n",
            "fold 2/13\n",
            "train\n",
            "Building model and compiling functions...\n",
            "Starting training...\n",
            "9\n",
            "01\n",
            "Epoch 1 of 5 took 429.622s\n",
            "  training loss:\t\t0.927946\n",
            "  validation loss:\t\t0.890101\n",
            "  validation accuracy:\t\t71.45 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.874784\n",
            "  test accuracy:\t\t69.53 %\n",
            "9\n",
            "01\n",
            "Epoch 2 of 5 took 429.154s\n",
            "  training loss:\t\t0.420501\n",
            "  validation loss:\t\t0.477885\n",
            "  validation accuracy:\t\t83.33 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.497726\n",
            "  test accuracy:\t\t80.42 %\n",
            "9\n",
            "01\n",
            "Epoch 3 of 5 took 423.743s\n",
            "  training loss:\t\t0.322720\n",
            "  validation loss:\t\t0.257668\n",
            "  validation accuracy:\t\t90.06 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.386914\n",
            "  test accuracy:\t\t91.90 %\n",
            "9\n",
            "01\n",
            "Epoch 4 of 5 took 426.157s\n",
            "  training loss:\t\t0.292986\n",
            "  validation loss:\t\t0.213847\n",
            "  validation accuracy:\t\t91.75 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.348063\n",
            "  test accuracy:\t\t89.60 %\n",
            "9\n",
            "01\n",
            "Epoch 5 of 5 took 424.146s\n",
            "  training loss:\t\t0.274975\n",
            "  validation loss:\t\t0.185264\n",
            "  validation accuracy:\t\t91.36 %\n",
            "--------------------------------------------------\n",
            "Best validation accuracy:\t\t91.75 %\n",
            "Best test accuracy:\t\t89.60 %\n",
            "fold 3/13\n",
            "train\n",
            "Building model and compiling functions...\n",
            "Starting training...\n",
            "9\n",
            "01\n",
            "Epoch 1 of 5 took 425.290s\n",
            "  training loss:\t\t0.893973\n",
            "  validation loss:\t\t0.612323\n",
            "  validation accuracy:\t\t79.94 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.695974\n",
            "  test accuracy:\t\t75.87 %\n",
            "9\n",
            "01\n",
            "Epoch 2 of 5 took 429.826s\n",
            "  training loss:\t\t0.413957\n",
            "  validation loss:\t\t0.370764\n",
            "  validation accuracy:\t\t83.26 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.410524\n",
            "  test accuracy:\t\t79.55 %\n",
            "9\n",
            "01\n",
            "Epoch 3 of 5 took 444.814s\n",
            "  training loss:\t\t0.335022\n",
            "  validation loss:\t\t0.273899\n",
            "  validation accuracy:\t\t89.36 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.320320\n",
            "  test accuracy:\t\t86.25 %\n",
            "9\n",
            "01\n",
            "Epoch 4 of 5 took 436.962s\n",
            "  training loss:\t\t0.303533\n",
            "  validation loss:\t\t0.283252\n",
            "  validation accuracy:\t\t87.34 %\n",
            "9\n",
            "01\n",
            "Epoch 5 of 5 took 426.516s\n",
            "  training loss:\t\t0.288000\n",
            "  validation loss:\t\t0.305279\n",
            "  validation accuracy:\t\t84.34 %\n",
            "--------------------------------------------------\n",
            "Best validation accuracy:\t\t89.36 %\n",
            "Best test accuracy:\t\t86.25 %\n",
            "fold 4/13\n",
            "train\n",
            "Building model and compiling functions...\n",
            "Starting training...\n",
            "9\n",
            "01\n",
            "Epoch 1 of 5 took 430.411s\n",
            "  training loss:\t\t0.966645\n",
            "  validation loss:\t\t0.494803\n",
            "  validation accuracy:\t\t80.22 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.385913\n",
            "  test accuracy:\t\t87.84 %\n",
            "9\n",
            "01\n",
            "Epoch 2 of 5 took 429.091s\n",
            "  training loss:\t\t0.483608\n",
            "  validation loss:\t\t0.287488\n",
            "  validation accuracy:\t\t87.91 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.160605\n",
            "  test accuracy:\t\t95.47 %\n",
            "9\n",
            "01\n",
            "Epoch 3 of 5 took 431.431s\n",
            "  training loss:\t\t0.375823\n",
            "  validation loss:\t\t0.196597\n",
            "  validation accuracy:\t\t90.97 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.076707\n",
            "  test accuracy:\t\t98.15 %\n",
            "9\n",
            "01\n",
            "Epoch 4 of 5 took 425.343s\n",
            "  training loss:\t\t0.328459\n",
            "  validation loss:\t\t0.185267\n",
            "  validation accuracy:\t\t92.44 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.069026\n",
            "  test accuracy:\t\t99.11 %\n",
            "9\n",
            "01\n",
            "Epoch 5 of 5 took 429.564s\n",
            "  training loss:\t\t0.320669\n",
            "  validation loss:\t\t0.174790\n",
            "  validation accuracy:\t\t93.46 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.068787\n",
            "  test accuracy:\t\t98.02 %\n",
            "--------------------------------------------------\n",
            "Best validation accuracy:\t\t93.46 %\n",
            "Best test accuracy:\t\t98.02 %\n",
            "fold 5/13\n",
            "train\n",
            "Building model and compiling functions...\n",
            "Starting training...\n",
            "9\n",
            "01\n",
            "Epoch 1 of 5 took 430.405s\n",
            "  training loss:\t\t1.118603\n",
            "  validation loss:\t\t0.729982\n",
            "  validation accuracy:\t\t70.60 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.345432\n",
            "  test accuracy:\t\t87.31 %\n",
            "9\n",
            "01\n",
            "Epoch 2 of 5 took 425.525s\n",
            "  training loss:\t\t0.553323\n",
            "  validation loss:\t\t0.329911\n",
            "  validation accuracy:\t\t84.89 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.106462\n",
            "  test accuracy:\t\t97.45 %\n",
            "9\n",
            "01\n",
            "Epoch 3 of 5 took 430.347s\n",
            "  training loss:\t\t0.398931\n",
            "  validation loss:\t\t0.276744\n",
            "  validation accuracy:\t\t86.67 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.065583\n",
            "  test accuracy:\t\t98.02 %\n",
            "9\n",
            "01\n",
            "Epoch 4 of 5 took 428.802s\n",
            "  training loss:\t\t0.333081\n",
            "  validation loss:\t\t0.272277\n",
            "  validation accuracy:\t\t86.67 %\n",
            "9\n",
            "01\n",
            "Epoch 5 of 5 took 428.752s\n",
            "  training loss:\t\t0.306290\n",
            "  validation loss:\t\t0.241807\n",
            "  validation accuracy:\t\t87.95 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.031613\n",
            "  test accuracy:\t\t98.85 %\n",
            "--------------------------------------------------\n",
            "Best validation accuracy:\t\t87.95 %\n",
            "Best test accuracy:\t\t98.85 %\n",
            "fold 6/13\n",
            "train\n",
            "Building model and compiling functions...\n",
            "Starting training...\n",
            "9\n",
            "01\n",
            "Epoch 1 of 5 took 425.844s\n",
            "  training loss:\t\t0.862590\n",
            "  validation loss:\t\t0.351804\n",
            "  validation accuracy:\t\t86.80 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.234851\n",
            "  test accuracy:\t\t92.98 %\n",
            "9\n",
            "01\n",
            "Epoch 2 of 5 took 429.443s\n",
            "  training loss:\t\t0.426985\n",
            "  validation loss:\t\t0.194269\n",
            "  validation accuracy:\t\t89.99 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.136088\n",
            "  test accuracy:\t\t95.96 %\n",
            "9\n",
            "01\n",
            "Epoch 3 of 5 took 427.892s\n",
            "  training loss:\t\t0.349303\n",
            "  validation loss:\t\t0.194944\n",
            "  validation accuracy:\t\t90.77 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.173873\n",
            "  test accuracy:\t\t95.86 %\n",
            "9\n",
            "01\n",
            "Epoch 4 of 5 took 425.461s\n",
            "  training loss:\t\t0.318299\n",
            "  validation loss:\t\t0.160064\n",
            "  validation accuracy:\t\t92.15 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.118269\n",
            "  test accuracy:\t\t96.37 %\n",
            "9\n",
            "01\n",
            "Epoch 5 of 5 took 429.231s\n",
            "  training loss:\t\t0.293913\n",
            "  validation loss:\t\t0.153311\n",
            "  validation accuracy:\t\t92.54 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.075613\n",
            "  test accuracy:\t\t97.62 %\n",
            "--------------------------------------------------\n",
            "Best validation accuracy:\t\t92.54 %\n",
            "Best test accuracy:\t\t97.62 %\n",
            "fold 7/13\n",
            "train\n",
            "Building model and compiling functions...\n",
            "Starting training...\n",
            "9\n",
            "01\n",
            "Epoch 1 of 5 took 433.655s\n",
            "  training loss:\t\t0.934041\n",
            "  validation loss:\t\t0.367582\n",
            "  validation accuracy:\t\t83.93 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.281036\n",
            "  test accuracy:\t\t90.18 %\n",
            "9\n",
            "01\n",
            "Epoch 2 of 5 took 433.767s\n",
            "  training loss:\t\t0.425985\n",
            "  validation loss:\t\t0.268818\n",
            "  validation accuracy:\t\t89.60 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.153850\n",
            "  test accuracy:\t\t95.03 %\n",
            "9\n",
            "01\n",
            "Epoch 3 of 5 took 428.431s\n",
            "  training loss:\t\t0.337917\n",
            "  validation loss:\t\t0.266007\n",
            "  validation accuracy:\t\t89.29 %\n",
            "9\n",
            "01\n",
            "Epoch 4 of 5 took 432.048s\n",
            "  training loss:\t\t0.300009\n",
            "  validation loss:\t\t0.229712\n",
            "  validation accuracy:\t\t88.78 %\n",
            "9\n",
            "01\n",
            "Epoch 5 of 5 took 431.802s\n",
            "  training loss:\t\t0.283360\n",
            "  validation loss:\t\t0.206127\n",
            "  validation accuracy:\t\t89.80 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.074135\n",
            "  test accuracy:\t\t97.70 %\n",
            "--------------------------------------------------\n",
            "Best validation accuracy:\t\t89.80 %\n",
            "Best test accuracy:\t\t97.70 %\n",
            "fold 8/13\n",
            "train\n",
            "Building model and compiling functions...\n",
            "Starting training...\n",
            "9\n",
            "01\n",
            "Epoch 1 of 5 took 424.564s\n",
            "  training loss:\t\t0.945758\n",
            "  validation loss:\t\t0.372661\n",
            "  validation accuracy:\t\t84.26 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.255196\n",
            "  test accuracy:\t\t90.19 %\n",
            "9\n",
            "01\n",
            "Epoch 2 of 5 took 428.828s\n",
            "  training loss:\t\t0.449916\n",
            "  validation loss:\t\t0.225448\n",
            "  validation accuracy:\t\t89.58 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.125150\n",
            "  test accuracy:\t\t95.69 %\n",
            "9\n",
            "01\n",
            "Epoch 3 of 5 took 431.655s\n",
            "  training loss:\t\t0.344947\n",
            "  validation loss:\t\t0.170715\n",
            "  validation accuracy:\t\t91.05 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.117923\n",
            "  test accuracy:\t\t96.07 %\n",
            "9\n",
            "01\n",
            "Epoch 4 of 5 took 429.643s\n",
            "  training loss:\t\t0.308827\n",
            "  validation loss:\t\t0.164744\n",
            "  validation accuracy:\t\t90.99 %\n",
            "9\n",
            "01\n",
            "Epoch 5 of 5 took 424.834s\n",
            "  training loss:\t\t0.290640\n",
            "  validation loss:\t\t0.147894\n",
            "  validation accuracy:\t\t92.73 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.058952\n",
            "  test accuracy:\t\t97.86 %\n",
            "--------------------------------------------------\n",
            "Best validation accuracy:\t\t92.73 %\n",
            "Best test accuracy:\t\t97.86 %\n",
            "fold 9/13\n",
            "train\n",
            "Building model and compiling functions...\n",
            "Starting training...\n",
            "9\n",
            "01\n",
            "Epoch 1 of 5 took 430.812s\n",
            "  training loss:\t\t1.029989\n",
            "  validation loss:\t\t0.632076\n",
            "  validation accuracy:\t\t78.11 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.505022\n",
            "  test accuracy:\t\t82.14 %\n",
            "9\n",
            "01\n",
            "Epoch 2 of 5 took 428.476s\n",
            "  training loss:\t\t0.465299\n",
            "  validation loss:\t\t0.315277\n",
            "  validation accuracy:\t\t87.95 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.196860\n",
            "  test accuracy:\t\t93.54 %\n",
            "9\n",
            "01\n",
            "Epoch 3 of 5 took 425.844s\n",
            "  training loss:\t\t0.358103\n",
            "  validation loss:\t\t0.187566\n",
            "  validation accuracy:\t\t92.02 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.107147\n",
            "  test accuracy:\t\t96.71 %\n",
            "9\n",
            "01\n",
            "Epoch 4 of 5 took 421.075s\n",
            "  training loss:\t\t0.314368\n",
            "  validation loss:\t\t0.170670\n",
            "  validation accuracy:\t\t92.59 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.086262\n",
            "  test accuracy:\t\t97.36 %\n",
            "9\n",
            "01\n",
            "Epoch 5 of 5 took 426.816s\n",
            "  training loss:\t\t0.288132\n",
            "  validation loss:\t\t0.165538\n",
            "  validation accuracy:\t\t92.77 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.080302\n",
            "  test accuracy:\t\t97.24 %\n",
            "--------------------------------------------------\n",
            "Best validation accuracy:\t\t92.77 %\n",
            "Best test accuracy:\t\t97.24 %\n",
            "fold 10/13\n",
            "train\n",
            "Building model and compiling functions...\n",
            "Starting training...\n",
            "9\n",
            "01\n",
            "Epoch 1 of 5 took 423.930s\n",
            "  training loss:\t\t0.960992\n",
            "  validation loss:\t\t0.539232\n",
            "  validation accuracy:\t\t78.40 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.577251\n",
            "  test accuracy:\t\t76.23 %\n",
            "9\n",
            "01\n",
            "Epoch 2 of 5 took 419.297s\n",
            "  training loss:\t\t0.460808\n",
            "  validation loss:\t\t0.438393\n",
            "  validation accuracy:\t\t80.41 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.324531\n",
            "  test accuracy:\t\t87.33 %\n",
            "9\n",
            "01\n",
            "Epoch 3 of 5 took 422.547s\n",
            "  training loss:\t\t0.352689\n",
            "  validation loss:\t\t0.390498\n",
            "  validation accuracy:\t\t84.65 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.242686\n",
            "  test accuracy:\t\t90.40 %\n",
            "9\n",
            "01\n",
            "Epoch 4 of 5 took 422.372s\n",
            "  training loss:\t\t0.326287\n",
            "  validation loss:\t\t0.353420\n",
            "  validation accuracy:\t\t85.27 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.140870\n",
            "  test accuracy:\t\t95.81 %\n",
            "9\n",
            "01\n",
            "Epoch 5 of 5 took 419.671s\n",
            "  training loss:\t\t0.294283\n",
            "  validation loss:\t\t0.306096\n",
            "  validation accuracy:\t\t85.44 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.154621\n",
            "  test accuracy:\t\t95.15 %\n",
            "--------------------------------------------------\n",
            "Best validation accuracy:\t\t85.44 %\n",
            "Best test accuracy:\t\t95.15 %\n",
            "fold 11/13\n",
            "train\n",
            "Building model and compiling functions...\n",
            "Starting training...\n",
            "9\n",
            "01\n",
            "Epoch 1 of 5 took 418.783s\n",
            "  training loss:\t\t0.903598\n",
            "  validation loss:\t\t0.432628\n",
            "  validation accuracy:\t\t83.42 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.351617\n",
            "  test accuracy:\t\t88.58 %\n",
            "9\n",
            "01\n",
            "Epoch 2 of 5 took 420.947s\n",
            "  training loss:\t\t0.427886\n",
            "  validation loss:\t\t0.234387\n",
            "  validation accuracy:\t\t89.48 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.196406\n",
            "  test accuracy:\t\t94.15 %\n",
            "9\n",
            "01\n",
            "Epoch 3 of 5 took 421.625s\n",
            "  training loss:\t\t0.342685\n",
            "  validation loss:\t\t0.218792\n",
            "  validation accuracy:\t\t89.69 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.167207\n",
            "  test accuracy:\t\t94.44 %\n",
            "9\n",
            "01\n",
            "Epoch 4 of 5 took 420.006s\n",
            "  training loss:\t\t0.315218\n",
            "  validation loss:\t\t0.197387\n",
            "  validation accuracy:\t\t90.16 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.187119\n",
            "  test accuracy:\t\t94.76 %\n",
            "9\n",
            "01\n",
            "Epoch 5 of 5 took 424.912s\n",
            "  training loss:\t\t0.291235\n",
            "  validation loss:\t\t0.242184\n",
            "  validation accuracy:\t\t90.01 %\n",
            "--------------------------------------------------\n",
            "Best validation accuracy:\t\t90.16 %\n",
            "Best test accuracy:\t\t94.76 %\n",
            "fold 12/13\n",
            "train\n",
            "Building model and compiling functions...\n",
            "Starting training...\n",
            "9\n",
            "01\n",
            "Epoch 1 of 5 took 429.171s\n",
            "  training loss:\t\t0.945867\n",
            "  validation loss:\t\t0.673900\n",
            "  validation accuracy:\t\t76.52 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.854363\n",
            "  test accuracy:\t\t67.51 %\n",
            "9\n",
            "01\n",
            "Epoch 2 of 5 took 428.038s\n",
            "  training loss:\t\t0.441730\n",
            "  validation loss:\t\t0.298868\n",
            "  validation accuracy:\t\t88.61 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.318036\n",
            "  test accuracy:\t\t87.50 %\n",
            "9\n",
            "01\n",
            "Epoch 3 of 5 took 424.211s\n",
            "  training loss:\t\t0.329903\n",
            "  validation loss:\t\t0.200343\n",
            "  validation accuracy:\t\t92.13 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.268420\n",
            "  test accuracy:\t\t90.29 %\n",
            "9\n",
            "01\n",
            "Epoch 4 of 5 took 425.756s\n",
            "  training loss:\t\t0.294869\n",
            "  validation loss:\t\t0.172197\n",
            "  validation accuracy:\t\t92.71 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.214753\n",
            "  test accuracy:\t\t92.62 %\n",
            "9\n",
            "01\n",
            "Epoch 5 of 5 took 427.149s\n",
            "  training loss:\t\t0.275718\n",
            "  validation loss:\t\t0.169700\n",
            "  validation accuracy:\t\t92.25 %\n",
            "--------------------------------------------------\n",
            "Best validation accuracy:\t\t92.71 %\n",
            "Best test accuracy:\t\t92.62 %\n",
            "fold 13/13\n",
            "train\n",
            "Building model and compiling functions...\n",
            "Starting training...\n",
            "9\n",
            "01\n",
            "Epoch 1 of 5 took 420.040s\n",
            "  training loss:\t\t0.812784\n",
            "  validation loss:\t\t0.555372\n",
            "  validation accuracy:\t\t85.13 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t1.019436\n",
            "  test accuracy:\t\t49.86 %\n",
            "9\n",
            "01\n",
            "Epoch 2 of 5 took 424.948s\n",
            "  training loss:\t\t0.383087\n",
            "  validation loss:\t\t0.324382\n",
            "  validation accuracy:\t\t90.83 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.898572\n",
            "  test accuracy:\t\t48.79 %\n",
            "9\n",
            "01\n",
            "Epoch 3 of 5 took 420.897s\n",
            "  training loss:\t\t0.287727\n",
            "  validation loss:\t\t0.261220\n",
            "  validation accuracy:\t\t91.45 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.852851\n",
            "  test accuracy:\t\t59.32 %\n",
            "9\n",
            "01\n",
            "Epoch 4 of 5 took 417.349s\n",
            "  training loss:\t\t0.264299\n",
            "  validation loss:\t\t0.244296\n",
            "  validation accuracy:\t\t92.65 %\n",
            "00\n",
            "Final results:\n",
            "  test loss:\t\t\t0.751590\n",
            "  test accuracy:\t\t52.48 %\n",
            "9\n",
            "01\n",
            "Epoch 5 of 5 took 420.472s\n",
            "  training loss:\t\t0.249615\n",
            "  validation loss:\t\t0.234798\n",
            "  validation accuracy:\t\t91.75 %\n",
            "--------------------------------------------------\n",
            "Best validation accuracy:\t\t92.65 %\n",
            "Best test accuracy:\t\t52.48 %\n",
            "****************************************\n",
            "Average MIX test accuracy: nan\n",
            "Average CNN test accuracy: 89.44500265765646\n",
            "****************************************\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}